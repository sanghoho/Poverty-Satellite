{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "satellite_image_analysis.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNdKDEKXuIX+YdhDb+zw5/N",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sanghoho/Poverty-Satellite/blob/master/satellite_image_analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0w6K7jo1Kp6N"
      },
      "source": [
        "## 구글 드라이브 연동"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KZJGiA08KcEF"
      },
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "drive.mount('/content/gdrive/', force_remount=True)\n",
        "os.chdir(\"gdrive/My Drive/20-satellite-olympic\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-jKmDdx6JxoK"
      },
      "source": [
        "## EasyEarh Class 정의"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gUTY-JmCKhqw"
      },
      "source": [
        "구름별 image sort 기준\n",
        "1. Copernicus : \"CLOUDY_PIXEL_PERCENTAGE\"\n",
        "2. Landsat : \"CLOUD_COVER\"\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L7h0wnyh_gpA"
      },
      "source": [
        "import ee\n",
        "import math\n",
        "\n",
        "import requests\n",
        "from PIL import Image\n",
        "from io import BytesIO\n",
        "\n",
        "try:\n",
        "  ee.initialize()\n",
        "except Exception as e:\n",
        "  ee.Authenticate()\n",
        "  ee.Initialize()\n",
        "\n",
        "\n",
        "class EasyEarth:\n",
        "  def __init__(self, dataset):\n",
        "    self.dataset = ee.ImageCollection(dataset)\n",
        "\n",
        "  def change_dataset(self, dataset):\n",
        "    self.dataset = ee.ImageCollection(dataset)\n",
        "\n",
        "  def select_AOI(self, lat, lon, k = 10, dates=None, cloud_name = \"CLOUD_COVER\" ,cloud_pct=None):\n",
        "    self.outer_AOI = self.__create_AOI(lat, lon, k / 50)\n",
        "    self.AOI = self.__create_AOI(lat, lon, k)\n",
        "    self.dates = dates\n",
        "    #해당 지역이 포함된 위성 사진 가져오기.\n",
        "    self.data_AOI = self.dataset.filterBounds(self.AOI)\n",
        "    #날짜 필터\n",
        "    if dates is not None:\n",
        "      self.data_AOI = self.__filter_dates(self.data_AOI, dates)\n",
        "    #구름필터\n",
        "    if cloud_pct is not None:\n",
        "      self.data_AOI = self.__filter_cloudy(by=cloud_name, cloud_pct=cloud_pct)\n",
        "    self.AOI_size = self.data_AOI.size().getInfo()\n",
        "    #self.data_AOI = self.data_AOI.map(cloudMask)\n",
        "\n",
        "  #대기효과 보정(구름제거)\n",
        "  def cloudMask(image) :\n",
        "    qa = image.select('QA60')\n",
        "    allCloudBitMask = (1 << 10) + (1 << 11)\n",
        "    mask = qa.bitwiseAnd(allCloudBitMask).eq(0)\n",
        "    return image.updateMask(mask);\n",
        "\n",
        "  def __create_AOI(self, lat, lon, s=10):\n",
        "    \"\"\"Creates a s km x s km square centered on (lat, lon)\"\"\"\n",
        "    v = (180/math.pi)*(500/6378137)*s # roughly 0.045 for s=10\n",
        "    self.geometry = ee.Geometry.Polygon([[[lon - v, lat + v],\n",
        "                                     [lon - v, lat - v],\n",
        "                                     [lon + v, lat - v],\n",
        "                                     [lon + v, lat + v]]], None, False)\n",
        "    return self.geometry #ee.Geometry.Rectangle([lon - v, lat - v, lon + v, lat + v])\n",
        "  def create_geo(self,lat,lon,s):\n",
        "    v = (180/math.pi)*(500/6378137)*s # roughly 0.045 for s=10\n",
        "    self.geometry = ee.Geometry.Polygon([[[lon - v, lat + v],\n",
        "                                     [lon - v, lat - v],\n",
        "                                     [lon + v, lat - v],\n",
        "                                     [lon + v, lat + v]]], None, False)\n",
        "    return self.geometry\n",
        "  def __filter_dates(self, col, dates):\n",
        "    return col.filterDate(dates[0], dates[1])\n",
        "\n",
        "\n",
        "  def __filter_cloudy(self, by=\"CLOUDY_PIXEL_PERCENTAGE\", cloud_pct=5):\n",
        "    \"\"\"\n",
        "    주로 Sentinel(COPERNIQUS)에서 구름 양을 조절하기 위해 사용합니다.\n",
        "    \"\"\"\n",
        "    return self.data_AOI.filter(ee.Filter.lt(by, cloud_pct))\n",
        "            \n",
        "\n",
        "  def sort_by(self, method = 'CLOUD_COVER', ascending=True):\n",
        "    sorted_collections = self.data_AOI.sort(method, ascending)\n",
        "    self.data_AOI = sorted_collections\n",
        "\n",
        "\n",
        "  def plot_image(self, img, paramters, cloud_name = 'CLOUD_COVER'):\n",
        "    \n",
        "    cloud_pct = img.get(cloud_name).getInfo()\n",
        "    # print(f'Cloud Cover (%): {cloud_pct}')\n",
        "\n",
        "    url = img.getThumbUrl(parameters)\n",
        "    response = requests.get(url)\n",
        "    \n",
        "    return cloud_pct, Image.open(BytesIO(response.content))\n",
        "\n",
        "\n",
        "  def get_collections_at(self, idx, collections=None):\n",
        "    if collections is not None:\n",
        "      size = collections.size().getInfo()\n",
        "      return ee.Image(collections.toList(size).get(idx)) \n",
        "    else:\n",
        "      return ee.Image(self.data_AOI.toList(self.AOI_size).get(idx))\n",
        "            \n",
        "  def save_image(self, save_path, image):\n",
        "    plt.imsave(save_path, np.array(image))\n",
        "    # print(str(save_path) + \" complete\")\n",
        "\n",
        "  def calculate_alpha_ratio(self, image):\n",
        "    img_array = np.array(image)\n",
        "    return np.sum(img_array == 0) / img_array.size\n",
        "    \n",
        "  def get_ndvi(self,image):\n",
        "    ndvi = image.normalizedDifference(['B8', 'B4']).rename('NDVI')\n",
        "    region = self.geometry\n",
        "    # Use a mean reducer.\n",
        "    reducer = ee.Reducer.mean()\n",
        "\n",
        "    # Compute the unweighted mean.\n",
        "    ndvi_value = ndvi.select(['NDVI']).reduceRegion(reducer, region, 10)\n",
        "    return ndvi_value.getInfo()['NDVI']\n",
        "  def get_ndbi(self,image):\n",
        "    ndbi = image.normalizedDifference(['B11', 'B8']).rename('NDBI')\n",
        "    region = self.geometry\n",
        "    # Use a mean reducer.\n",
        "    reducer = ee.Reducer.mean()\n",
        "\n",
        "    # Compute the unweighted mean.\n",
        "    ndbi_value = ndbi.select(['NDBI']).reduceRegion(reducer, region, 10)\n",
        "    return ndbi_value.getInfo()['NDBI']\n",
        "  \n",
        "  def get_ui(self,image):\n",
        "     Ndvi = image.normalizedDifference(['B8', 'B4'])\n",
        "     Ndbi = image.normalizedDifference(['B11', 'B8'])\n",
        "     Ui = Ndbi.subtract(Ndvi).rename('Ui');\n",
        "     region = self.geometry\n",
        "     reducer = ee.Reducer.mean()\n",
        "     Ui_value = Ui.select(['Ui']).reduceRegion(reducer, region, 10)\n",
        "     return Ui_value.getInfo()['Ui']\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sHHHGOiO2NnL"
      },
      "source": [
        "def create_geo(lat,lon,s = 10):\n",
        "    v = (180/math.pi)*(500/6378137)*s # roughly 0.045 for s=10\n",
        "    geometry = ee.Geometry.Polygon([[[lon - v, lat + v],\n",
        "                                    [lon - v, lat - v],\n",
        "                                    [lon + v, lat - v],\n",
        "                                    [lon + v, lat + v]]], None, False)\n",
        "    return geometry\n",
        "\n",
        "\n",
        "#평창 군청\n",
        "lat = 37.370814 \n",
        "lon = 128.390359\n",
        "\n",
        "a = create_geo(lat,lon)\n",
        "a"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v45SsxbeW8nY"
      },
      "source": [
        "v = (180/math.pi)*(500/6378137)*10 # roughly 0.045 for s=10\n",
        "a = ee.Geometry.Rectangle([lon - v, lat - v, lon + v, lat + v])\n",
        "print(a)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZaF4gEniYxMi"
      },
      "source": [
        "parameters = {\n",
        "  'min': 0.0,\n",
        "  'max': 2500,\n",
        "  'bands': ['B4', 'B3', 'B2'],\n",
        "  'dimensions': 512,\n",
        "  'region': earth.AOI\n",
        "}\n",
        "\n",
        "earth.sort_by(\"CLOUDY_PIXEL_PERCENTAGE\")\n",
        "\n",
        "least_cloudy_img = earth.get_collections_at(1)\n",
        "\n",
        "cloud , img = earth.plot_image(least_cloudy_img.resample('bicubic'), parameters, \"CLOUDY_PIXEL_PERCENTAGE\")\n",
        "\n",
        "print(cloud)\n",
        "img"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NU6Jh63ZVvc0"
      },
      "source": [
        "least_cloudy_img.toArray()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iQxqsxvxVwja"
      },
      "source": [
        "nir = least_cloudy_img.select('B8')\n",
        "red = least_cloudy_img.select('B4')\n",
        "ndvi = nir.subtract(red).divide(nir.add(red)).rename('NDVI')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9SOZ_sVt8l9e"
      },
      "source": [
        "### Sentinel 위성 이미지 추출"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kzm_3wEQC-s6"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import math\n",
        "from datetime import datetime as dt\n",
        "def range_year(year):\n",
        "  return f\"{year}-04-01\", f\"{year}-05-01\"\n",
        "earth = EasyEarth('COPERNICUS/S2')\n",
        "CLOUD_NAME = \"CLOUDY_PIXEL_PERCENTAGE\" # \"CLOUD_COVER\"\n",
        "#알펜시아\n",
        "#lat = 37.658251\n",
        "#lon = 128.669856\n",
        "#진부역\n",
        "#lat = 37.642935\n",
        "#lon = 128.574451\n",
        "#올림픽 게이트웨이\n",
        "#lat = 37.668117\n",
        "#lon = 128.705676\n",
        "#자연휴양\n",
        "#lat = 37.705692\n",
        "#lon = 128.720683\n",
        "#평창역\n",
        "#lat = 37.562846\n",
        "#lon = 128.429930\n",
        "#평창군청\n",
        "lat = 37.370814 \n",
        "lon = 128.390359\n",
        "save_df = pd.DataFrame(columns=[\"raw_name\", \"lat\", \"lon\", \"image_name\", \"cloud_pct\",\"year\",\"time\",\"NDVI\",\"NDBI\",\"UI\"])\n",
        "image_list = []\n",
        "for year in [\"2016\",\"2017\",\"2018\",\"2019\",\"2020\"]:\n",
        "  name = f\"{lat}_{lon}_{year}.png\" \n",
        "  if(year == \"2017\"):\n",
        "    earth.select_AOI(lat,lon, 10, (\"2017-04-15\", \"2017-05-01\"), CLOUD_NAME, 10)\n",
        "  elif (year ==\"2018\"):\n",
        "    earth.select_AOI(lat,lon, 10, (\"2018-04-01\", \"2018-04-19\"), CLOUD_NAME, 10)\n",
        "  elif (year == '2020'):\n",
        "    earth.select_AOI(lat,lon, 10, (\"2020-04-28\", \"2020-04-30\"), CLOUD_NAME, 10)\n",
        "  else :\n",
        "    earth.select_AOI(lat,lon, 10, range_year(year), CLOUD_NAME, 10)\n",
        "  \n",
        "  earth.data_AOI.map(cloudMask)\n",
        "  parameters = {\n",
        "    'min': 0.0,\n",
        "    'max': 3000,\n",
        "    'bands': ['B4', 'B3', 'B2'],\n",
        "    'dimensions': 512,\n",
        "    'region': earth.AOI\n",
        "  }\n",
        "  earth.sort_by(CLOUD_NAME)\n",
        "  least_cloudy_img = earth.get_collections_at(0)\n",
        "  ndvi = earth.get_ndvi(least_cloudy_img)\n",
        "  ndbi = earth.get_ndbi(least_cloudy_img)\n",
        "  ui = earth.get_ui(least_cloudy_img)\n",
        "  cloud_pct, least_result = earth.plot_image(least_cloudy_img.resample('bicubic'), parameters, CLOUD_NAME)\n",
        "  image_list.append(least_result)\n",
        "  date = ee.Date(least_cloudy_img.get('system:time_start'))\n",
        "  time = date.getInfo()['value']/1000\n",
        "  \n",
        "  # 메타 정보 데이터프레임에 저장\n",
        "  tmp_result = pd.Series({\"raw_name\" : least_cloudy_img.getInfo()['id'],\"lat\": lat, \"lon\": lon,  \"image_name\": name,  \"cloud_pct\": cloud_pct,\n",
        "                            \"year\": year, \"time\" : dt.utcfromtimestamp(time).strftime('%Y-%m-%d %H:%M:%S'),\"NDVI\" : ndvi,\"NDBI\" : ndbi,\"UI\" : ui}).to_frame().T\n",
        "  save_df = save_df.append(tmp_result,ignore_index=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qzpoJwcFt4sP"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import math\n",
        "from datetime import datetime as dt\n",
        "def range_year(year):\n",
        "  return f\"{year}-04-01\", f\"{year}-05-01\"\n",
        "earth = EasyEarth('COPERNICUS/S2')\n",
        "CLOUD_NAME = \"CLOUDY_PIXEL_PERCENTAGE\" # \"CLOUD_COVER\"\n",
        "#알펜시아\n",
        "#lat = 37.658251\n",
        "#lon = 128.669856\n",
        "#진부역\n",
        "#lat = 37.642935\n",
        "#lon = 128.574451\n",
        "#올림픽 게이트웨이\n",
        "#lat = 37.668117\n",
        "#lon = 128.705676\n",
        "#자연휴양\n",
        "#lat = 37.705692\n",
        "#lon = 128.720683\n",
        "#평창역\n",
        "#lat = 37.562846\n",
        "#lon = 128.429930\n",
        "#평창군청\n",
        "lat = 37.370814 \n",
        "lon = 128.390359\n",
        "save_df = pd.DataFrame(columns=[\"raw_name\", \"lat\", \"lon\", \"image_name\", \"cloud_pct\",\"year\",\"time\",\"NDVI\",\"NDBI\",\"UI\"])\n",
        "image_list = []\n",
        "earth.select_AOI(lat,lon, 10, range_year(2016), CLOUD_NAME, 10)\n",
        "parameters = {\n",
        "    'min': 0.0,\n",
        "    'max': 3000,\n",
        "    'bands': ['B4', 'B3', 'B2'],\n",
        "    'dimensions': 512,\n",
        "    'region': earth.AOI\n",
        "  }\n",
        "earth.sort_by(CLOUD_NAME)\n",
        "least_cloudy_img = earth.get_collections_at(0)\n",
        "ndvi = earth.get_ndvi(least_cloudy_img)\n",
        "ndbi = earth.get_ndbi(least_cloudy_img)\n",
        "ui = earth.get_ui(least_cloudy_img)\n",
        "cloud_pct, least_result = earth.plot_image(least_cloudy_img.resample('bicubic'), parameters, CLOUD_NAME)\n",
        "image_list.append(least_result)\n",
        "date = ee.Date(least_cloudy_img.get('system:time_start'))\n",
        "time = date.getInfo()['value']/1000\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_isE_RD-mQIb"
      },
      "source": [
        "\n",
        "\n",
        "task = ee.batch.Export.image.toDrive(**{\n",
        "  'image': least_cloudy_img,\n",
        "  'description': 'imageToCOGeoTiffExample',\n",
        "  'scale': 30,\n",
        "  'fileFormat': 'GeoTIFF',\n",
        "  'formatOptions': {\n",
        "    'cloudOptimized': True \n",
        "  }\n",
        "});\n",
        "\n",
        "task.start()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mJlLHl2ZnaEo"
      },
      "source": [
        "task = ee.batch.Export.image.toDrive(image = least_cloudy_img,description = 'didididi')\n",
        "\n",
        "task.start()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lce6LHfez-vO"
      },
      "source": [
        "landsat = ee.Image('LANDSAT/LC08/C01/T1_TOA/LC08_123032_20140515').select(['B4', 'B3', 'B2']);\n",
        "\n",
        "geometry = ee.Geometry.Rectangle([116.2621, 39.8412, 116.4849, 40.01236]);\n",
        "\n",
        "ee.batch.Export.image.toDrive(**{\n",
        "  'image': landsat,\n",
        "  'description': 'imageToDriveExample',\n",
        "  'scale': 30,\n",
        "});"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Lgj5U62wg2D"
      },
      "source": [
        "google earth에서 행정구역 대로 자르기(google earth engine code editor에 들어가서 asset에 shapefile을 업로드 해야한다)\n",
        "\n",
        "참고 자료: https://developers.google.com/earth-engine/importing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nJ8w_By0bjzE"
      },
      "source": [
        "table= ee.FeatureCollection(\"users/jinwoo95/pyeongchang\")\n",
        "area = table.getInfo()['features'][0]['geometry']\n",
        "collection = ee.ImageCollection(\"COPERNICUS/S2\").filterBounds(area)\\\n",
        "                                      .filterDate(\"2018-01-01\",\"2019-01-10\")\\\n",
        "                                      .filterMetadata(\"CLOUDY_PIXEL_PERCENTAGE\",\"less_than\",10)\\\n",
        "                                      .select(['B8', 'B4'])\n",
        "print(\" number of image: \",collection.size().getInfo())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rJFTB52HSTkL"
      },
      "source": [
        "table.map"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j21RNI6trcF_"
      },
      "source": [
        "Test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V0ydhak_ZfXS"
      },
      "source": [
        "from osgeo import gdal\n",
        "from matplotlib import pyplot as plt\n",
        "import sys\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4G2zxrEdyhbL"
      },
      "source": [
        "earth = EasyEarth('COPERNICUS/S2')\n",
        "lat = 37.5624\n",
        "lon = 128.4293\n",
        "##위도,경도,반경 몇키로, 날짜, image_sort기준, 구름 몇 %이하로 설정할 것인지\n",
        "earth.select_AOI(lat,lon, 5, (\"2018-04-01\", \"2018-10-31\"), \"CLOUDY_PIXEL_PERCENTAGE\", 10)\n",
        "parameters = {\n",
        "  'min': 0.0,\n",
        "  'max': 2500,\n",
        "  'bands': ['B4', 'B3', 'B2'],\n",
        "  'dimensions': 512,\n",
        "  'region': earth.AOI\n",
        "}\n",
        "\n",
        "earth.sort_by(\"CLOUDY_PIXEL_PERCENTAGE\")\n",
        "\n",
        "least_cloudy_img = earth.get_collections_at(0)\n",
        "\n",
        "cloud , img = earth.plot_image(least_cloudy_img.resample('bicubic'), parameters, \"CLOUDY_PIXEL_PERCENTAGE\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "33ZD7pMeSkS2"
      },
      "source": [
        "earth = EasyEarth('COPERNICUS/S2')\n",
        "lat = 37.5624\n",
        "lon = 128.4293\n",
        "geometry = earth.create_geo(lat,lon,10)\n",
        "'''year = 2019\n",
        "image = (ee.ImageCollection('COPERNICUS/S2')\n",
        "              .filterBounds(geometry)\n",
        "              .filterDate('2017-04-15','2017-05-15')\n",
        "              .sort('CLOUDY_PIXEL_PERCENTAGE')\n",
        "              .first()\n",
        "              .clip(geometry))\n",
        "              '''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QMnpS93b4un7"
      },
      "source": [
        "# 새 섹션"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NM_5TIbAay8x"
      },
      "source": [
        "earth = EasyEarth('COPERNICUS/S2')\n",
        "image = (earth.dataset\n",
        "                 .filterBounds(geometry)\n",
        "                 .filterDate('2020-04-15','2020-05-15')\n",
        "                .sort('CLOUDY_PIXEL_PERCENTAGE')\n",
        "                .first()\n",
        "                .clip(geometry))\n",
        "                 \n",
        "                  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AuZ865c_b9gl"
      },
      "source": [
        "image.getInfo()['id']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XV9JVxmKLxQb"
      },
      "source": [
        "least_cloudy_img.getInfo()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U8BSfMz_utKD"
      },
      "source": [
        "위성 영상 전처리 in google earth : https://developers.google.com/earth-engine/landsat\n",
        "\n",
        "위성 영상 전처리 개념 정리 글 : https://m.blog.naver.com/PostView.nhn?blogId=rsmilee&logNo=220648092210&proxyReferer=https:%2F%2Fwww.google.com%2F"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IR5BiwsW3H8a"
      },
      "source": [
        "머신러닝을 이용한 위성사진 분류 (supervised learning)  \n",
        "\n",
        "구글 어스 엔진을 사용한 논문 : https://www.frontiersin.org/articles/10.3389/feart.2017.00017/full"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fDAbmcp13Tvw"
      },
      "source": [
        "1) Naive Bayes\n",
        "\n",
        "---\n",
        "process sequence\n",
        "\n",
        "1. google earth engine에서 그리기를 통해 직접 훈련 데이터 셋을 만든다(직접 만드는 방법 말고 훈련 데이터 집합 이미지를 직접 저장해놓고 있는 경우도 있다). 각각의 클래스에 해당하는 픽셀을 여러개 지정한다.  \n",
        "\n",
        "2. classifier를 설정한다. 필요하다면 파라미터도 설정하지만 Naive-Bayes 에서는 지정해야할 파라미터가 없기 때문에 생략한다.\n",
        "\n",
        "3. 훈련 데이터셋을 통해서 classifier를 학습시킨다.\n",
        "\n",
        "4. 이미지 데이터 셋 분류를 실시한다.\n",
        "\n",
        "5. validation set을 통해 분류 오류율을 체크한다.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ch1CbW7N3XLQ"
      },
      "source": [
        "#시각화 패키지 설치\n",
        "import subprocess\n",
        "\n",
        "try:\n",
        "    import geemap\n",
        "except ImportError:\n",
        "    print('geemap package not installed. Installing ...')\n",
        "    subprocess.check_call([\"python\", '-m', 'pip', 'install', 'geemap'])\n",
        "\n",
        "# Checks whether this notebook is running on Google Colab\n",
        "try:\n",
        "    import google.colab\n",
        "    import geemap.eefolium as geemap\n",
        "except:\n",
        "    import geemap"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OtukcbmsW-3-"
      },
      "source": [
        "#동적 맵 생성하기.\n",
        "Map = geemap.Map(center=[40,-100], zoom=4)\n",
        "Map"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wQGKk80kpki7"
      },
      "source": [
        "# 분류하기"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7qMMcPElSR4I"
      },
      "source": [
        "1. 인풋이 되는 위성 사진(TIF)을 추출한다.\n",
        "2. 딥러닝을 위해 해당 JPG사진을 다운로드 한다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kMBM8g3KSOZ4"
      },
      "source": [
        "#분류 전 데이터 학습 및 검증하기\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import math\n",
        "from datetime import datetime as dt\n",
        "def range_year(year):\n",
        "  return f\"{year}-04-15\", f\"{year}-05-15\"\n",
        "earth = EasyEarth('COPERNICUS/S2')\n",
        "CLOUD_NAME = \"CLOUDY_PIXEL_PERCENTAGE\" # \"CLOUD_COVER\"\n",
        "#알펜시아\n",
        "#lat = 37.658251\n",
        "#lon = 128.669856\n",
        "#진부역\n",
        "#lat = 37.642935\n",
        "#lon = 128.574451\n",
        "#올림픽 게이트웨이\n",
        "#lat = 37.668117\n",
        "#lon = 128.705676\n",
        "#자연휴양\n",
        "#lat = 37.705692\n",
        "#lon = 128.720683\n",
        "#평창역\n",
        "lat = 37.562846\n",
        "lon = 128.429930\n",
        "\n",
        "save_df = pd.DataFrame(columns=[\"lat\", \"lon\", \"image_name\",  \"cloud_pct\",\"year\",\"time\",\"NDVI\",\"NDBI\"])\n",
        "image_list = []\n",
        "\n",
        "for year in [\"2016\",\"2017\",\"2018\",\"2019\",\"2020\"]:\n",
        "  \n",
        "  name = f\"{lat}_{lon}_{year}.png\" \n",
        "  if(year == \"2017\"):\n",
        "    earth.select_AOI(lat,lon, 10, (\"2017-04-12\", \"2017-04-15\"), CLOUD_NAME, 10)\n",
        "  else :\n",
        "    earth.select_AOI(lat,lon, 10, range_year(year), CLOUD_NAME, 10)\n",
        "  \n",
        "  parameters = {\n",
        "    'min': 0.0,\n",
        "    'max': 3000,\n",
        "    'bands': ['B4', 'B3', 'B2'],\n",
        "    'dimensions': 512,\n",
        "    'region': earth.AOI\n",
        "  }\n",
        "  earth.sort_by(CLOUD_NAME)\n",
        "\n",
        "  least_cloudy_img = earth.get_collections_at(0)\n",
        "  ndvi = earth.get_ndvi(least_cloudy_img)\n",
        "  ndbi = earth.get_ndbi(least_cloudy_img)\n",
        "  ui = earth.get_ui(least_cloudy_img)\n",
        "  cloud_pct, least_result = earth.plot_image(least_cloudy_img.resample('bicubic'), parameters, CLOUD_NAME)\n",
        "  image_list.append(least_result)\n",
        "  date = ee.Date(least_cloudy_img.get('system:time_start'))\n",
        "  time = date.getInfo()['value']/1000.\n",
        "  \n",
        "  # 메타 정보 데이터프레임에 저장\n",
        "  tmp_result = pd.Series({\"lat\": lat, \"lon\": lon,  \"image_name\": name,  \"cloud_pct\": cloud_pct,\n",
        "                            \"year\": year, \"time\" : dt.utcfromtimestamp(time).strftime('%Y-%m-%d %H:%M:%S'),\"NDVI\" : ndvi,\"NDBI\" : ndbi,\"UI\" : ui}).to_frame().T\n",
        "  save_df = save_df.append(tmp_result,ignore_index=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pgMX2Ui4S_LE"
      },
      "source": [
        "image_list[4]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bf4X8eynSuhC"
      },
      "source": [
        "#위성 이미지 불러오기\n",
        "earth = EasyEarth('COPERNICUS/S2')\n",
        "lat = 37.647125\n",
        "lon = 128.685141\n",
        "##위도,경도,반경 몇키로, 날짜, image_sort기준, 구름 몇 %이하로 설정할 것인지\n",
        "earth.select_AOI(lat,lon, 100, (\"2020-04-01\", \"2020-04-30\"), \"CLOUDY_PIXEL_PERCENTAGE\", 10)\n",
        "parameters = {\n",
        "  'min': 0.0,\n",
        "  'max': 2500,\n",
        "  'bands': ['B4', 'B3', 'B2'],\n",
        "  'dimensions': 512,\n",
        "  'region': earth.AOI\n",
        "}\n",
        "earth.sort_by(\"CLOUDY_PIXEL_PERCENTAGE\")\n",
        "\n",
        "image = earth.get_collections_at(0)\n",
        "##training set 가져오기\n",
        "points= ee.FeatureCollection(\"users/jinwoo95/training_point\")\n",
        "\n",
        "#area = table.getInfo()['features'][0]\n",
        "bands = [\"B2\",\"B3\",\"B4\",\"B5\",\"B6\",\"B7\"]\n",
        "#label은 훈련 데이터 셋에 각 class를 지정할 때 property명임.\n",
        "label = 'lc'\n",
        "#train, test_set 나누기.\n",
        "\n",
        "data_set = image.select(bands).sampleRegions(**{\n",
        "  'collection': points,\n",
        "  'properties': [label],\n",
        "  'scale': 1000\n",
        "})\n",
        "\n",
        "sample = data_set.randomColumn()\n",
        "split = 0.7  \n",
        "training = sample.filter(ee.Filter.lt('random', split))\n",
        "validation = sample.filter(ee.Filter.gte('random', split))\n",
        "\n",
        "# Train a CART classifier with default parameters.\n",
        "classifier = ee.Classifier.cart().train(**{\n",
        " 'features': training , \n",
        "  'classProperty': label,\n",
        "  'inputProperties': bands\n",
        "})\n",
        "# Classify the image with the same bands used for training.\n",
        "classified = image.select(bands).classify(classifier)\n",
        "\n",
        "# Display the inputs and the results.\n",
        "#Map.centerObject(points, 11)\n",
        "#Map.addLayer(classified,\n",
        "#             {'min': 0, 'max': 3, 'palette': ['#0b4a8b', '#ffc82d', '#00ffff','#bf04c2','#ff0000']},\n",
        "#           'classification')\n",
        "\n",
        "#Map\n",
        "trainAccuracy = classifier.confusionMatrix();\n",
        "\n",
        "validated = validation.classify(classifier)\n",
        "testAccuracy = validated.errorMatrix('lc', 'classification')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WyVDl7UuTNNk"
      },
      "source": [
        "#위성 이미지 불러오기\n",
        "earth = EasyEarth('COPERNICUS/S2')\n",
        "lat = 37.647125\n",
        "lon = 128.685141\n",
        "##위도,경도,반경 몇키로, 날짜, image_sort기준, 구름 몇 %이하로 설정할 것인지\n",
        "ee.ImageCollection('COPERNICUS/S2_SR')\n",
        "                .filterBounds(region)\n",
        "                .filterDate('2019-04-01', '2019-04-30')\n",
        "                .sort('CLOUDY_PIXEL_PERCENTAGE')\n",
        "                .first();\n",
        "earth.select_AOI(lat,lon, 10, (\"2020-04-01\", \"2020-04-30\"), \"CLOUDY_PIXEL_PERCENTAGE\", 10)\n",
        "parameters = {\n",
        "  'min': 0.0,\n",
        "  'max': 2500,\n",
        "  'bands': ['B4', 'B3', 'B2'],\n",
        "  'dimensions': 512,\n",
        "  'region': earth.AOI\n",
        "}\n",
        "earth.sort_by(\"CLOUDY_PIXEL_PERCENTAGE\")\n",
        "\n",
        "image = earth.get_collections_at(0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jnV9zHOMTWuJ"
      },
      "source": [
        "cloud_pct, least_result = earth.plot_image(image.resample('bicubic'), parameters, CLOUD_NAME)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Z7grkvFfe86"
      },
      "source": [
        "table= ee.FeatureCollection(\"users/jinwoo95/pyeongchang\")\n",
        "#table.getInfo()\n",
        "#area = table.getInfo()['features'][0]['geometry']['coordinates']\n",
        "type(table.getInfo())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "68iEsSFuiPk-"
      },
      "source": [
        "### Decision Tree 학습법"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4E9xBCfjZL6H"
      },
      "source": [
        "region = ee.Geometry.Polygon([[[\n",
        "                128.30838423579402,\n",
        "                37.480315764205976\n",
        "              ],\n",
        "              [\n",
        "                128.30838423579402,\n",
        "                37.39048423579403\n",
        "              ],\n",
        "              [\n",
        "                128.39821576420596,\n",
        "                37.39048423579403\n",
        "              ],\n",
        "              [\n",
        "                128.39821576420596,\n",
        "                37.480315764205976\n",
        "              ]\n",
        "            ]])\n",
        "#평창군 행정구역\n",
        "table= ee.FeatureCollection(\"users/jinwoo95/pyeongchang\")\n",
        "area = table.getInfo()['features'][0]['geometry']['coordinates']\n",
        "roi = ee.Geometry.Polygon(area)\n",
        "image = (ee.ImageCollection('COPERNICUS/S2')\n",
        "                .filterBounds(region)\n",
        "                .filterDate('2019-04-01', '2019-04-30')\n",
        "                .sort('CLOUDY_PIXEL_PERCENTAGE')\n",
        "                .first()\n",
        "                .clip(roi))\n",
        "##data set 가져오기\n",
        "points= ee.FeatureCollection(\"users/jinwoo95/revised_training3\")\n",
        "\n",
        "#area = table.getInfo()['features'][0]\n",
        "#bands = [\"B1\",\"B2\",\"B3\",\"B4\",\"B5\",\"B6\",\"B7\",\"B8\",\"B9\",\"B11\",\"B12\"]\n",
        "#bands = [\"B1\",\"B2\",\"B3\",\"B4\",\"B5\",\"B6\",\"B7\",\"B8\",\"B8A\",\"B9\",\"B10\",\"B11\",\"B12\"]\n",
        "bands = [\"B4\",\"B8\",\"B11\"]\n",
        "#label은 훈련 데이터 셋에 각 class를 지정할 때 property명임.\n",
        "label = 'class'\n",
        "#train, test_set 나누기.\n",
        "\n",
        "data_set = image.select(bands).sampleRegions(**{\n",
        "  'collection': points,\n",
        "  'properties': [label],\n",
        "  'scale': 10\n",
        "})\n",
        "\n",
        "sample = data_set.randomColumn()\n",
        "split = 0.7  \n",
        "training = sample.filter(ee.Filter.lt('random', split))\n",
        "validation = sample.filter(ee.Filter.gte('random', split))\n",
        "\n",
        "# Train a CART classifier with default parameters.\n",
        "classifier = ee.Classifier.cart().train(**{\n",
        " 'features': training , \n",
        "  'classProperty': label,\n",
        "  'inputProperties': bands\n",
        "})\n",
        "# Classify the image with the same bands used for training.\n",
        "classified = image.select(bands).classify(classifier)\n",
        "\n",
        "# Display the inputs and the results.\n",
        "#Map.centerObject(points, 11)\n",
        "#Map.addLayer(classified,\n",
        "#             {'min': 0, 'max': 3, 'palette': ['#0b4a8b', '#ffc82d', '#00ffff','#bf04c2','#ff0000']},\n",
        "#           'classification')\n",
        "\n",
        "#Map\n",
        "trainAccuracy = classifier.confusionMatrix();\n",
        "\n",
        "validated = validation.classify(classifier)\n",
        "testAccuracy = validated.errorMatrix('class', 'classification')\n",
        "#image = image2.select('B4', 'B3', 'B2')\n",
        "#Map.addLayer(image, {'gain': [1.4, 1.4, 1.1]}, 'Landsat 7')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "86m0bALeEtr6"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5chYUnBh_3yL"
      },
      "source": [
        "print(data_set.size().getInfo())\n",
        "#print(training.size().getInfo())\n",
        "#print(validation.size().getInfo())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rozxcgeu_bSz"
      },
      "source": [
        "print(trainAccuracy.accuracy().getInfo())\n",
        "#print(trainAccuracy.getInfo())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S8WPlCui-RSM"
      },
      "source": [
        "print(testAccuracy.accuracy().getInfo())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V8Ibs91spw3W"
      },
      "source": [
        "print(testAccuracy.getInfo())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-fO-SReOiVYB"
      },
      "source": [
        "### Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lqZK0yd9dYZJ"
      },
      "source": [
        "# Train a CART classifier with default parameters.\n",
        "classifier = (ee.Classifier.smileRandomForest(10)\n",
        "    .train(**{\n",
        "      'features': training,\n",
        "      'classProperty': label,\n",
        "      'inputProperties': bands}));\n",
        "# Classify the image with the same bands used for training.\n",
        "classified = image.select(bands).classify(classifier)\n",
        "\n",
        "# Display the inputs and the results.\n",
        "#Map.centerObject(points, 11)\n",
        "#Map.addLayer(classified,\n",
        "#             {'min': 0, 'max'  : 3, 'palette': ['#0b4a8b', '#ffc82d', '#00ffff','#bf04c2','#ff0000']},\n",
        "#           'classification')\n",
        "\n",
        "#Map\n",
        "trainAccuracy = classifier.confusionMatrix();\n",
        "\n",
        "validated = validation.classify(classifier)\n",
        "testAccuracy = validated.errorMatrix('class', 'classification')\n",
        "#image = image2.select('B4', 'B3', 'B2')\n",
        "#Map.addLayer(image, {'gain': [1.4, 1.4, 1.1]}, 'Landsat 7')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5OYeRkzTp2CY"
      },
      "source": [
        "print(trainAccuracy.accuracy().getInfo())\n",
        "#print(trainAccuracy.getInfo())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JOoqTdC2p2Ca"
      },
      "source": [
        "print(testAccuracy.accuracy().getInfo())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PlhX1VUrp2Cc"
      },
      "source": [
        "print(testAccuracy.getInfo())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JgpyCK9cksig"
      },
      "source": [
        "### SVM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bK7cntbNj_f0"
      },
      "source": [
        "\n",
        "\"\"\"classifier = (ee.Classifier.libsvm(**{\n",
        "  'kernelType': 'RBF',\n",
        "  'gamma': 0.5,\n",
        "  'cost': 10})\n",
        "    .train(**{\n",
        "      'features': training,\n",
        "      'classProperty': label,\n",
        "      'inputProperties': bands}));\"\"\"\n",
        "classifier = (ee.Classifier.libsvm()\n",
        "    .train(**{\n",
        "      'features': training,\n",
        "      'classProperty': label,\n",
        "      'inputProperties': bands}));\n",
        "# Classify the image with the same bands used for training.\n",
        "classified = image.select(bands).classify(classifier)\n",
        "trainAccuracy = classifier.confusionMatrix();\n",
        "\n",
        "validated = validation.classify(classifier)\n",
        "testAccuracy = validated.errorMatrix('class', 'classification')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fh2g2Rldp-ai"
      },
      "source": [
        "print(trainAccuracy.accuracy().getInfo())\n",
        "#print(trainAccuracy.getInfo())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2G1_M78Ep-ak"
      },
      "source": [
        "print(testAccuracy.accuracy().getInfo())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r-q4IDznp-an"
      },
      "source": [
        "print(testAccuracy.getInfo())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hLWSUNpMnea6"
      },
      "source": [
        "### Naive Bayes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xWfZJHVT37Gu"
      },
      "source": [
        "classifier = (ee.Classifier.naiveBayes().train(**{\n",
        "      'features': training,\n",
        "      'classProperty': label,\n",
        "      'inputProperties': bands}));\n",
        "# Classify the image with the same bands used for training.\n",
        "classified = image.select(bands).classify(classifier)\n",
        "trainAccuracy = classifier.confusionMatrix();\n",
        "\n",
        "validated = validation.classify(classifier)\n",
        "testAccuracy = validated.errorMatrix('class', 'classification')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hvr8SMn--mra"
      },
      "source": [
        "print(trainAccuracy.accuracy().getInfo())\n",
        "#print(trainAccuracy.getInfo())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vr1wPXhr-k5q"
      },
      "source": [
        "print(testAccuracy.accuracy().getInfo())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CYDPhlTS5oJ5"
      },
      "source": [
        "print(testAccuracy.getInfo())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PvuY2CdKDfur"
      },
      "source": [
        "## 특정 구역 연도별 class 변화 살펴보기(random forest 사용)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PNKs381fDpIi"
      },
      "source": [
        "### 1.알펜시아 용평 리조트"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QhFs7N9aKoaJ"
      },
      "source": [
        "#분류 전 데이터 학습 및 검증하기\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import math\n",
        "from datetime import datetime as dt\n",
        "def range_year(year):\n",
        "  return f\"{year}-04-15\", f\"{year}-05-15\"\n",
        "#알펜시아\n",
        "lat = 37.658251\n",
        "lon = 128.669856\n",
        "#진부역\n",
        "#lat = 37.642935\n",
        "#lon = 128.574451\n",
        "#올림픽 게이트웨이\n",
        "#lat = 37.668117\n",
        "#lon = 128.705676\n",
        "#자연휴양\n",
        "#lat = 37.705692\n",
        "#lon = 128.720683\n",
        "#평창역\n",
        "#lat = 37.562846\n",
        "#lon = 128.429930\n",
        "earth = EasyEarth('COPERNICUS/S2')\n",
        "CLOUD_NAME = \"CLOUDY_PIXEL_PERCENTAGE\" # \"CLOUD_COVER\"\n",
        "\n",
        "bands = ['B1', 'B2', 'B3', 'B4', 'B5', 'B6', 'B7', 'B8']\n",
        "save_df = pd.DataFrame(columns=[\"lat\", \"lon\", \"image_name\",\"cloud_pct\",\"year\",\"time\",\"Classified\",\"Geometry\"])\n",
        "image_list = []\n",
        "\n",
        "for year in [\"2016\",\"2017\",\"2018\",\"2019\",\"2020\"]:\n",
        "  \n",
        "  name = f\"{lat}_{lon}_{year}.png\" \n",
        "  if(year == \"2017\"):\n",
        "    earth.select_AOI(lat,lon, 10, (\"2017-04-12\", \"2017-04-15\"), CLOUD_NAME, 10)\n",
        "  else :\n",
        "    earth.select_AOI(lat,lon, 10, range_year(year), CLOUD_NAME, 10)\n",
        "  \n",
        "  parameters = {\n",
        "    'min': 0.0,\n",
        "    'max': 3000,\n",
        "    'bands': ['B4', 'B3', 'B2'],\n",
        "    'dimensions': 512,\n",
        "    'region': earth.AOI\n",
        "  }\n",
        "  \n",
        "  geometry = earth.AOI\n",
        "  earth.sort_by(CLOUD_NAME)\n",
        "  least_cloudy_img = earth.get_collections_at(0)\n",
        "  least_cloudy_img = least_cloudy_img.clip(earth.AOI)\n",
        "  classified = least_cloudy_img.select(bands).classify(classifier)\n",
        "  cloud_pct, least_result = earth.plot_image(least_cloudy_img.resample('bicubic'), parameters, CLOUD_NAME)\n",
        "  image_list.append(least_result)\n",
        "  date = ee.Date(least_cloudy_img.get('system:time_start'))\n",
        "  time = date.getInfo()['value']/1000.\n",
        "  \n",
        "  #학습된 모델로 이미지 분류\n",
        "\n",
        "  # 메타 정보 데이터프레임에 저장\n",
        "  tmp_result = pd.Series({\"lat\": lat, \"lon\": lon,  \"image_name\": name,  \"cloud_pct\": cloud_pct,\n",
        "                            \"year\": year, \"time\" : dt.utcfromtimestamp(time).strftime('%Y-%m-%d %H:%M:%S'),\"Classified\" :classified,\"Geometry\":geometry}).to_frame().T\n",
        "  save_df = save_df.append(tmp_result,ignore_index=True)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2x0sKXF2fIvB"
      },
      "source": [
        "#save_df['Classified'][0].getInfo()\n",
        "#classified.getInfo()\n",
        "least_result"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uJm6pV4pvHHQ"
      },
      "source": [
        "save_df['Classified'][4].getInfo()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eajWXtvdyiDd"
      },
      "source": [
        "#image = ee.Image(collection.sort('CLOUD_COVER').first()\n",
        "lat = 37.658251\n",
        "lon = 128.669856\n",
        "CLOUD_NAME='CLOUDY_PIXEL_PERCENTAGE'\n",
        "earth = EasyEarth('COPERNICUS/S2_SR')\n",
        "geometry = earth.create_geo(lat,lon,10)\n",
        "year = 2019\n",
        "image = (ee.ImageCollection('COPERNICUS/S2_SR')\n",
        "              .filterBounds(geometry)\n",
        "              #.filterDate(f'{year}-04-14', f'{year}-05-15')\n",
        "              .filterDate('2017-04-13','2017-04-14')\n",
        "              .sort('CLOUDY_PIXEL_PERCENTAGE')\n",
        "              .first()\n",
        "              .clip(geometry))\n",
        "parameters = {\n",
        "  'min': 0.0,\n",
        "  'max': 3000,\n",
        "  'bands': ['B4', 'B3', 'B2'],\n",
        "  'dimensions': 512,\n",
        "  'region': geometry\n",
        "}\n",
        "cloud_pct, least_result = earth.plot_image(image.resample('bicubic'), parameters, CLOUD_NAME)\n",
        "from datetime import datetime as dt\n",
        "date = ee.Date(image.get('system:time_start'))\n",
        "time = date.getInfo()['value']/1000.\n",
        "print(dt.utcfromtimestamp(time).strftime('%Y-%m-%d %H:%M:%S'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yw2ivJN2PpEi"
      },
      "source": [
        "#image = ee.Image(collection.sort('CLOUD_COVER').first()\n",
        "lat = 37.658251\n",
        "lon = 128.669856\n",
        "CLOUD_NAME='CLOUDY_PIXEL_PERCENTAGE'\n",
        "earth = EasyEarth('COPERNICUS/S2_SR')\n",
        "geometry = earth.create_geo(lat,lon,10)\n",
        "year = 2019\n",
        "region = ee.Geometry.Polygon([[[\n",
        "                128.30838423579402,\n",
        "                37.480315764205976\n",
        "              ],\n",
        "              [\n",
        "                128.30838423579402,\n",
        "                37.39048423579403\n",
        "              ],\n",
        "              [\n",
        "                128.39821576420596,\n",
        "                37.39048423579403\n",
        "              ],\n",
        "              [\n",
        "                128.39821576420596,\n",
        "                37.480315764205976\n",
        "              ]\n",
        "            ]])\n",
        "image = (ee.ImageCollection('COPERNICUS/S2_SR')\n",
        "              .filterBounds(region)\n",
        "              #.filterDate(f'{year}-04-14', f'{year}-05-15')\n",
        "              .filterDate('2017-04-13','2017-04-14')\n",
        "              .sort('CLOUDY_PIXEL_PERCENTAGE')\n",
        "              .first()\n",
        "              .clip(geometry))\n",
        "parameters = {\n",
        "  'min': 0.0,\n",
        "  'max': 3000,\n",
        "  'bands': ['B4', 'B3', 'B2'],\n",
        "  'dimensions': 512,\n",
        "  'region': geometry\n",
        "}\n",
        "#cloud_pct, least_result = earth.plot_image(image.resample('bicubic'), parameters, CLOUD_NAME)\n",
        "from datetime import datetime as dt\n",
        "date = ee.Date(image.get('system:time_start'))\n",
        "time = date.getInfo()['value']/1000.\n",
        "print(dt.utcfromtimestamp(time).strftime('%Y-%m-%d %H:%M:%S'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H7mFg-ahKnRz"
      },
      "source": [
        "lat = 37.658251\n",
        "lon = 128.669856\n",
        "earth = EasyEarth('COPERNICUS/S2_SR')\n",
        "geometry = earth.create_geo(lat,lon,10)\n",
        "year = 2019\n",
        "image = (ee.ImageCollection('COPERNICUS/S2')\n",
        "              .filterBounds(geometry)\n",
        "              .filterDate('2017-04-15','2017-05-15')\n",
        "              .sort('CLOUDY_PIXEL_PERCENTAGE')\n",
        "              .first()\n",
        "              .clip(geometry))\n",
        "'''from datetime import datetime as dt\n",
        "date = ee.Date(image.get('system:time_start'))\n",
        "time = date.getInfo()['value']/1000.\n",
        "print(dt.utcfromtimestamp(time).strftime('%Y-%m-%d %H:%M:%S'))'''\n",
        "classified = image.select(bands).classify(classifier)\n",
        "Map.centerObject(points, 11)\n",
        "Map.addLayer(classified, {'min': 0, 'max': 3, 'palette': ['#0b4a8b', '#ffc82d', '#00ffff','#bf04c2']},\n",
        "          'classification')\n",
        "Map"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x5UgMfxLxHx_"
      },
      "source": [
        "### 각 토지 이용변화 비율 추출하기"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dOZknopvwV3_"
      },
      "source": [
        "### 농업 : 0 , 도시 : 1, 수역: 2, 숲 :3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TQCwC_v4fzzi"
      },
      "source": [
        "#시각화 패키지 설치\n",
        "import subprocess\n",
        "\n",
        "try:\n",
        "    import geemap\n",
        "except ImportError:\n",
        "    print('geemap package not installed. Installing ...')\n",
        "    subprocess.check_call([\"python\", '-m', 'pip', 'install', 'geemap'])\n",
        "\n",
        "# Checks whether this notebook is running on Google Colab\n",
        "try:\n",
        "    import google.colab\n",
        "    import geemap.eefolium as geemap\n",
        "except:\n",
        "    import geemap"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a4c0ku4ZZu2H"
      },
      "source": [
        "#동적 맵 생성하기.\n",
        "Map = geemap.Map(center=[40,-100], zoom=4)\n",
        "Map"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g7JoGy9hLtJb"
      },
      "source": [
        "#table= ee.FeatureCollection(\"users/jinwoo95/pyeongchang\")\n",
        "#area = table.getInfo()['features'][0]['geometry']['coordinates']\n",
        "#roi = ee.Geometry.Polygon(area)\n",
        "#classified = image.select(bands).classify(classifier)\n",
        "#least_cloudy_img= save_df.loc[0,'Classified'].clip(roi)\n",
        "# Display the inputs and the results.\n",
        "#classified = classified.clip(region)\n",
        "#earth = EasyEarth('COPERNICUS/S2_SR')\n",
        "#lat = 37.647125\n",
        "#lon = 128.685141\n",
        "'''region = ee.Geometry.Polygon([[[\n",
        "                128.30838423579402,\n",
        "                37.480315764205976\n",
        "              ],\n",
        "              [\n",
        "                128.30838423579402,\n",
        "                37.39048423579403\n",
        "              ],\n",
        "              [\n",
        "                128.39821576420596,\n",
        "                37.39048423579403\n",
        "              ],\n",
        "              [\n",
        "                128.39821576420596,\n",
        "                37.480315764205976\n",
        "              ]\n",
        "            ]])\n",
        "\n",
        "#image = (ee.ImageCollection('COPERNICUS/S2_SR')\n",
        "                .filterBounds(region)\n",
        "                .filterDate('2019-04-01', '2019-04-30')\n",
        "                .sort('CLOUDY_PIXEL_PERCENTAGE')\n",
        "                .first()\n",
        "                .clip(region))\n",
        "'''\n",
        "##위도,경도,반경 몇키로, 날짜, image_sort기준, 구름 몇 %이하로 설정할 것인지\n",
        "#earth.select_AOI(lat,lon, 10, (\"2018-04-01\", \"2018-04-30\"), \"CLOUDY_PIXEL_PERCENTAGE\", 10)\n",
        "#earth.sort_by('CLOUDY_PIXEL_PERCENTAGE')\n",
        "#k = earth.get_cimg()\n",
        "#classified = image.select(bands).classify(classifier)\n",
        "#classified = least_cloudy_img.select(bands).classify(classifier)\n",
        "Map.centerObject(points, 11)\n",
        "Map.addLayer(save_df['Classified'][0], {'min': 0, 'max': 3, 'palette': ['#0b4a8b', '#ffc82d', '#00ffff','#bf04c2']},\n",
        "          'classification')\n",
        "Map"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wuGW5zt1wdTD"
      },
      "source": [
        "from datetime import datetime as dt\n",
        "date = ee.Date(k.get('system:time_start'))\n",
        "time = date.getInfo()['value']/1000.\n",
        "time = dt.utcfromtimestamp(time).strftime('%Y-%m-%d %H:%M:%S')\n",
        "print(time)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dlYPaDfeYwjT"
      },
      "source": [
        "fallowedBinary = classified2010.eq(3).and(classified2015.eq(2));\n",
        "Map.addLayer(fallowedBinary);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4E_LJxy6govM"
      },
      "source": [
        "least_result"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HDSTAki0n68s"
      },
      "source": [
        "#areaImageSqM = ee.Image.clip(roi);\n",
        "Map.centerObject(points, 11)\n",
        "Map.addLayer(classified,{'min': 0, 'max': 3, 'palette': ['#0b4a8b', '#ffc82d', '#00ffff','#bf04c2']},\n",
        "           'classification')\n",
        "\n",
        "Map"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QrbSIFJAqZfL"
      },
      "source": [
        "classified"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bwX4ed_mgYV-"
      },
      "source": [
        "least_cloudy_img.getInfo()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u3MNSmRsg524"
      },
      "source": [
        "### 클래스 별 변화 살펴보기 TEST\n",
        "농업 : 0 , 도시 : 1, 수역: 2, 숲 :3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n3Ttm4MzeUG5"
      },
      "source": [
        "a = save_df['Classified'][0]\n",
        "b = save_df['Classified'][4]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "556JLCMHg3HZ"
      },
      "source": [
        "#바뀐 지역\n",
        "a = save_df['Classified'][0]\n",
        "b = save_df['Classified'][4]\n",
        "fallowedBinary = (a.eq(3)_and(b.eq(1)));\n",
        "areaImageSqM = (ee.Image.pixelArea()\n",
        "\t.clip(save_df['Geometry'][0]))\n",
        "areaImageSqKm = areaImageSqM.multiply(0.000001);\n",
        "fallowedArea = fallowedBinary.multiply(areaImageSqKm);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "adabY4FBzTw4"
      },
      "source": [
        "save_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z4xPS2PXg4H0"
      },
      "source": [
        "#바뀐 지역\n",
        "a = save_df['Classified'][4]\n",
        "b = save_df['Classified'][0]\n",
        "roi = save_df['Geometry'][0]\n",
        "fallowedBinary = a.eq(3).And(b.eq(1));\n",
        "#fallowedBinary = (a.eq(3) and (b.eq(1)));\n",
        "areaImageSqM = (ee.Image.pixelArea()\n",
        "\t.clip(roi))\n",
        "areaImageSqKm = areaImageSqM.multiply(0.000001);\n",
        "fallowedArea = fallowedBinary.multiply(areaImageSqKm);\n",
        "reducer = ee.Reducer.sum()\n",
        "geometry = roi\n",
        "scale = 30\n",
        "totalFallowedArea = fallowedArea.reduceRegion(reducer,geometry,scale)\n",
        "'''totalFallowedArea = (fallowedArea.reduceRegion({'reducer': ee.Reducer.sum(),\n",
        "\t'geometry' : roi,\n",
        "\t'scale': 30,\n",
        "  'maxPixels': 1e9}))\n",
        "'''\n",
        "print('Total fallowed area, sq km: ', totalFallowedArea.values().getInfo())\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oyiul38uqojS"
      },
      "source": [
        "#동적 맵 생성하기.\n",
        "Map = geemap.Map(center=[40,-100], zoom=4)\n",
        "Map"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vUmB1JVuwoVV"
      },
      "source": [
        "roi = save_df['Geometry'][0]\n",
        "isinstance(roi,ee.ComputedObject)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-IluC-mWDIGR"
      },
      "source": [
        "print(totalFallowedArea.values().getInfo())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tNpVSKv8DM_c"
      },
      "source": [
        "save_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KGyVvy-zLYam"
      },
      "source": [
        "a = save_df['Classified'][0]\n",
        "b = save_df['Classified'][4]\n",
        "fallowedBinary = (a.eq(3).And(b.eq(0)));\n",
        "Map.centerObject(points, 11)\n",
        "Map.addLayer(fallowedBinary,\n",
        "             {'min': 0, 'max': 3, 'palette': ['#0b4a8b', '#ffc82d']},\n",
        "           'classification')\n",
        "\n",
        "Map"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Z0BJLh7MuGr"
      },
      "source": [
        "Map = geemap.Map(center=[40,-100], zoom=4)\n",
        "Map"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dy7NxnGwNf1u"
      },
      "source": [
        "Map = geemap.Map(center=[40,-100], zoom=4)\n",
        "agri = classified.eq(1)\n",
        "Map.centerObject(points, 11)\n",
        "Map.addLayer(agri,\n",
        " {'min':0, 'max':1, 'palette': ['grey', 'blue']},\n",
        " 'Built-Up')\n",
        "Map "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NWt1VJZXM7G9"
      },
      "source": [
        "a = classified.reduce(ee.Reducer.median())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CcOSbaIBbqWu"
      },
      "source": [
        "a."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lLniYu3tBDqL"
      },
      "source": [
        "### 클래스별 면적 계산"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gUJw9PqJh-3I"
      },
      "source": [
        "areaImage = (ee.Image.pixelArea().addBands(\n",
        "      classified))\n",
        "areas = (areaImage.reduceRegion(\n",
        "    reducer =  ee.Reducer.sum().group(groupField = 1,groupName = 'class'),\n",
        "    geometry =  geometry,\n",
        "    scale= 500,\n",
        "    maxPixels =  1e10\n",
        "    ));\n",
        "#print(areas.getInfo())\n",
        "each_class = areas.getInfo()\n",
        "sum = round(each_class['groups'][0]['sum'] + each_class['groups'][1]['sum'] +each_class['groups'][2]['sum']+each_class['groups'][3]['sum'])\n",
        "\n",
        "agri =  round(round(each_class['groups'][0]['sum']) / sum *100,2)\n",
        "urban = round(round(each_class['groups'][1]['sum']) / sum*100,2)\n",
        "water = round(round(each_class['groups'][2]['sum']) / sum*100,2)\n",
        "forest = round(round(each_class['groups'][3]['sum']) / sum*100,2)\n",
        "print(agri, urban, water, forest)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-N9XPSjlZZk9"
      },
      "source": [
        "classAreas = ee.List(areas.get('groups'))\n",
        "\n",
        "def k(item) :\n",
        "  areaDict = ee.Dictionary(item)\n",
        "  classNumber = ee.Number(areaDict.get('class')).format()\n",
        "  area = ee.Number(areaDict.get('sum')).divide(1e6).round()\n",
        "  return ee.List([classNumber, area])\n",
        "\n",
        "classAreaLists = classAreas.map(k)\n",
        "result = ee.Dictionary(classAreas.map(classAreaLists.flatten()))\n",
        "print(result.values().getInfo())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W9WsBDzVBo2I"
      },
      "source": [
        "### 클래스별 면적 후처리"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GQrC_oVR9ZPC"
      },
      "source": [
        "nestedList = ee.List(areas.getInfo())\n",
        "#print(nestedList) \n",
        "print(nestedList.flatten().getInfo())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WR_sdfkBKQ-P"
      },
      "source": [
        "classAreas = ee.List(areas.get('groups'))\n",
        "\n",
        "def k(item) :\n",
        "  areaDict = ee.Dictionary(item)\n",
        "  classNumber = ee.Number(areaDict.get('class')).format()\n",
        "  area = ee.Number(areaDict.get('sum')).divide(1e6).round()\n",
        "  return ee.List([classNumber, area])\n",
        "\n",
        "classAreaLists = classAreas.map(k)\n",
        "result = ee.Dictionary(classAreas.map(classAreaLists.flatten()))\n",
        "print(result.values())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ag5spsVKXI1"
      },
      "source": [
        "def calculateClassArea(feature) :\n",
        "    areas = ee.Image.pixelArea().addBands(classified).reduceRegion(**{\n",
        "      'reducer': ee.Reducer.sum().group(**{\n",
        "      'groupField': 1,\n",
        "      'groupName': 'class',\n",
        "    }),\n",
        "    'geometry': geometry,\n",
        "    'scale': 500,\n",
        "    'maxPixels': 1e10\n",
        "    })\n",
        "    classAreas = ee.List(areas.get('groups'))\n",
        "    classAreaLists = classAreas.map(k)\n",
        "    result = ee.Dictionary(classAreaLists.flatten())\n",
        "    district = feature.get('ADM2_NAME')\n",
        "    return ee.Feature(\n",
        "      feature.geometry(),\n",
        "      result.set('district', district))\n",
        "    \n",
        "districtAreas = ee.List(geometry).map(calculateClassArea);\n",
        "print(districtAreas.values())\n",
        "'''\n",
        "var districtAreas = kerala.map(calculateClassArea);  \n",
        "\n",
        "calculateClassArea = function(feature) {\n",
        "    var areas = ee.Image.pixelArea().addBands(classified)\n",
        "    .reduceRegion({\n",
        "      reducer: ee.Reducer.sum().group({\n",
        "      groupField: 1,\n",
        "      groupName: 'class',\n",
        "    }),\n",
        "    geometry: feature.geometry(),\n",
        "    scale: 500,\n",
        "    maxPixels: 1e10\n",
        "    })\n",
        " \n",
        "    var classAreas = ee.List(areas.get('groups'))\n",
        "    var classAreaLists = classAreas.map(function(item) {\n",
        "      var areaDict = ee.Dictionary(item)\n",
        "      var classNumber = ee.Number(\n",
        "        areaDict.get('class')).format()\n",
        "      var area = ee.Number(\n",
        "        areaDict.get('sum')).divide(1e6).round()\n",
        "      return ee.List([classNumber, area])\n",
        "    })\n",
        " \n",
        "    var result = ee.Dictionary(classAreaLists.flatten())\n",
        "    var district = feature.get('ADM2_NAME')\n",
        "    return ee.Feature(\n",
        "      feature.geometry(),\n",
        "      result.set('district', district))\n",
        "}\n",
        " \n",
        "var districtAreas = kerala.map(calculateClassArea);\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tSi9ocfLOFy0"
      },
      "source": [
        "stateArea = geometry.area()\n",
        "stateAreaSqKm = ee.Number(stateArea).divide(1e6).round()\n",
        "print(stateAreaSqKm)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ALzY3g8ePaDD"
      },
      "source": [
        "geometry.getInfo()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SDBSoEhuTrCD"
      },
      "source": [
        "areaImage = (ee.Image.pixelArea().addBands(\n",
        "      classified))\n",
        "areas = (areaImage.reduceRegion(\n",
        "    reducer =  ee.Reducer.sum().group(groupField = 1,groupName = 'class'),\n",
        "    geometry =  geometry,\n",
        "    scale= 500,\n",
        "    maxPixels =  1e10\n",
        "    )); \n",
        " \n",
        "\n",
        "print(areas.getInfo())\n",
        "classAreas = ee.List(areas.get('groups'))\n",
        "\n",
        "def k(item) :\n",
        "  areaDict = ee.Dictionary(item)\n",
        "  classNumber = ee.Number(areaDict.get('class')).format()\n",
        "  area = ee.Number(areaDict.get('sum')).divide(1e6).round()\n",
        "  return ee.List([classNumber, area])\n",
        "\n",
        "classAreaLists = classAreas.map(k)\n",
        "result = ee.Dictionary(classAreas.map(classAreaLists.flatten()))\n",
        "print(result.values().getInfo())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iOlED89Nq_CI"
      },
      "source": [
        "### 테스트"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G56F6ASbwcra"
      },
      "source": [
        "#분류 전 데이터 학습 및 검증하기\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import math\n",
        "from datetime import datetime as dt\n",
        "def range_year(year):\n",
        "  return f\"{year}-04-01\", f\"{year}-05-01\"\n",
        "#알펜시아\n",
        "#lat = 37.658251\n",
        "#lon = 128.669856\n",
        "#진부역\n",
        "#lat = 37.642935\n",
        "#lon = 128.574451\n",
        "#올림픽 게이트웨이\n",
        "#lat = 37.668117\n",
        "#lon = 128.705676\n",
        "#자연휴양\n",
        "#lat = 37.705692\n",
        "#lon = 128.720683\n",
        "#평창역\n",
        "lat = 37.562846\n",
        "lon = 128.429930\n",
        "earth = EasyEarth('COPERNICUS/S2')\n",
        "CLOUD_NAME = \"CLOUDY_PIXEL_PERCENTAGE\" # \"CLOUD_COVER\"\n",
        "bands = ['B1', 'B2', 'B3', 'B4', 'B5', 'B6', 'B7', 'B8',\"B8A\",\"B9\",\"B10\",\"B11\",\"B12\"]\n",
        "#badns = [\"B4\",\"B8\",\"B11\"]\n",
        "save_df = pd.DataFrame(columns=[\"image_list\",\"lat\", \"lon\", \"image_name\",\"cloud_pct\",\"year\",\"time\",\"NDVI\",\"NDBI\",\"UI\",\"Agri\",\"Urban\",\"Water\",\"Forest\",\"Classified\"])\n",
        "image_list = []\n",
        "def cloudMask(image) :\n",
        "  qa = image.select('QA60')\n",
        "  allCloudBitMask = (1 << 10) + (1 << 11)\n",
        "  mask = qa.bitwiseAnd(allCloudBitMask).eq(0)\n",
        "  return image.updateMask(mask);\n",
        "for year in [\"2016\",\"2017\",\"2018\",\"2019\",\"2020\"]:\n",
        "  name = f\"{lat}_{lon}_{year}.png\" \n",
        "  if (year == \"2016\") :\n",
        "    earth.select_AOI(lat,lon, 10, (\"2016-04-16\", \"2016-04-28\"), CLOUD_NAME, 10)\n",
        "  elif (year == \"2017\"):\n",
        "    earth.select_AOI(lat,lon, 10, (\"2017-04-15\", \"2017-05-01\"), CLOUD_NAME, 10)\n",
        "  elif (year ==\"2018\"):\n",
        "    earth.select_AOI(lat,lon, 10, (\"2018-04-01\", \"2018-04-19\"), CLOUD_NAME, 10)\n",
        "  elif ( year == \"2020\"):\n",
        "    earth.select_AOI(lat,lon, 10, (\"2020-04-15\", \"2020-05-15\"), CLOUD_NAME, 10)\n",
        "  else :\n",
        "    earth.select_AOI(lat,lon, 10, range_year(year), CLOUD_NAME, 10)\n",
        "\n",
        "  parameters = {\n",
        "    'min': 0.0,\n",
        "    'max': 3000,\n",
        "    'bands': ['B4', 'B3', 'B2'],\n",
        "    'dimensions': 512,\n",
        "    'region': earth.AOI\n",
        "  }\n",
        "  #earth.data_AOI.map(cloudMask)\n",
        "  geometry = earth.AOI\n",
        "  earth.sort_by(CLOUD_NAME)\n",
        "  least_cloudy_img = earth.get_collections_at(0)\n",
        "  least_cloudy_img = least_cloudy_img.clip(earth.AOI)\n",
        "  cloud_pct, least_result = earth.plot_image(least_cloudy_img.resample('bicubic'), parameters, CLOUD_NAME)\n",
        "  date = ee.Date(least_cloudy_img.get('system:time_start'))\n",
        "  time = date.getInfo()['value']/1000.\n",
        "  classified = least_cloudy_img.select(bands).classify(classifier)\n",
        "  ndvi = earth.get_ndvi(least_cloudy_img)\n",
        "  ndbi = earth.get_ndbi(least_cloudy_img)\n",
        "  ui = earth.get_ui(least_cloudy_img)\n",
        "  cloud_pct, least_result = earth.plot_image(least_cloudy_img.resample('bicubic'), parameters, CLOUD_NAME)\n",
        "  image_list.append(least_result)\n",
        "  \n",
        "  #클래스 별 면적 구하기\n",
        "  areaImage = (ee.Image.pixelArea().addBands(\n",
        "      classified))\n",
        "  areas = (areaImage.reduceRegion(\n",
        "    reducer =  ee.Reducer.sum().group(groupField = 1,groupName = 'class'),\n",
        "    geometry =  geometry,\n",
        "    scale= 500,\n",
        "    maxPixels =  1e10\n",
        "    ));\n",
        "  each_class = areas.getInfo()\n",
        "  if(len(each_class['groups']) == 4) :\n",
        "    sum = round(each_class['groups'][0]['sum'] + each_class['groups'][1]['sum'] +each_class['groups'][2]['sum']+each_class['groups'][3]['sum'])\n",
        "    agri =  round(round(each_class['groups'][0][' sum']) / sum *100,2)\n",
        "    urban = round(round(each_class['groups'][1]['sum']) / sum*100,2)\n",
        "    water = round(round(each_class['groups'][2]['sum']) / sum*100,2)\n",
        "    forest = round(round(each_class['groups'][3]['sum']) / sum*100,2)\n",
        "  elif(len(each_class['groups'])==3):\n",
        "    sum = round(each_class['groups'][0]['sum'] + each_class['groups'][1]['sum'] +each_class['groups'][2]['sum'])\n",
        "    agri =  round(round(each_class['groups'][0]['sum']) / sum *100,2)\n",
        "    urban = round(round(each_class['groups'][1]['sum']) / sum*100,2)\n",
        "    water = 0\n",
        "    forest = round(round(each_class['groups'][2]['sum']) / sum*100,2)\n",
        "                \n",
        "\n",
        "  #학습된 모델로 이미지 분류\n",
        "\n",
        "  # 메타 정보 데이터프레임에 저장\n",
        "  tmp_result = pd.Series({\"image_list\" : least_result,\"lat\": lat, \"lon\": lon,  \"image_name\": name,  \"cloud_pct\": cloud_pct,\n",
        "                            \"year\": year, \"time\" : dt.utcfromtimestamp(time).strftime('%Y-%m-%d %H:%M:%S'),\"NDVI\" : ndvi,\"NDBI\": ndbi,\"UI\": ui,\"Agri\":agri,\"Urban\" : urban,\"Water\" : water,\"Forest\" : forest,\"Clssified\": classified}).to_frame().T\n",
        "  save_df = save_df.append(tmp_result,ignore_index=True)\n",
        "\n",
        "save_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WSC1VKf3Au3t"
      },
      "source": [
        "from matplotlib import pyplot as plt\n",
        "x = [2016,2017,2018,2019,2020]\n",
        "y =  save_df['Agri']\n",
        "y1 = save_df['Urban']\n",
        "y2 = save_df['Water']\n",
        "y3 = save_df['Forest']\n",
        "plt.figure(figsize = (8,8)) \n",
        "plt.plot(x,y)\n",
        "plt.plot(x,y1)\n",
        "plt.plot(x,y2)\n",
        "plt.plot(x,y3)\n",
        "plt.legend(['Agriculture', 'Urban','Water','Forest'])\n",
        "# 화면에 그래프를 보여줍니다\n",
        "plt.grid(10)\n",
        "plt.xticks([2016 ,2017, 2018, 2019 ,2020])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nFreT5kpF1X_"
      },
      "source": [
        "#동적 맵 생성하기.\n",
        "Map = geemap.Map(center=[40,-100], zoom=4)\n",
        "Map\n",
        "\n",
        "classified = save_df['Clssified'][0]\n",
        "Map.centerObject(points, 11)\n",
        "Map.addLayer(classified, {'min': 0, 'max': 3, 'palette': ['#0b4a8b', '#ffc82d', '#00ffff','#bf04c2']},\n",
        "          'classification')\n",
        "Map"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Oc4XGXp4nn2"
      },
      "source": [
        "save_df['image_list'][4]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h-d42alwFUzI"
      },
      "source": [
        "save_df['image_list'][2]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4m_eWlPEI3vG"
      },
      "source": [
        "save_df['image_list'][3]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EHE4-MS54zWB"
      },
      "source": [
        "py = "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3vK95qUT5SIt"
      },
      "source": [
        "## 평창행정구역 별로 clip한 후 데이터 획득하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AnTf8ANMCrDQ"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import math\n",
        "from datetime import datetime as dt\n",
        "#table= ee.FeatureCollection(\"users/jinwoo95/pyeongchang\")\n",
        "table= ee.FeatureCollection(\"users/jinwoo95/hwacheon\")\n",
        "area = table.getInfo()['features'][0]['geometry']['coordinates']\n",
        "roi = ee.Geometry.Polygon(area)\n",
        "image = (ee.ImageCollection('COPERNICUS/S2')\n",
        "              .filterBounds(roi)\n",
        "              .sort('CLOUDY_PIXEL_PERCENTAGE')\n",
        "              .filterDate(\"2016-04-16\", \"2016-04-28\")\n",
        "              .first()\n",
        "              .clip(roi))\n",
        "def range_year(year):\n",
        "  return f\"{year}-04-01\", f\"{year}-05-01\"\n",
        "def get_ndvi(image,roi):\n",
        "  ndvi = image.normalizedDifference(['B8', 'B4']).rename('NDVI')\n",
        "  region = roi\n",
        "  # Use a mean reducer.\n",
        "  reducer = ee.Reducer.mean()\n",
        "\n",
        "  # Compute the unweighted mean.\n",
        "  ndvi_value = ndvi.select(['NDVI']).reduceRegion(**{ 'reducer': ee.Reducer.mean(),\n",
        "  'geometry': roi,\n",
        "  'maxPixels': 1e9})\n",
        "  return ndvi_value.getInfo()['NDVI']\n",
        "def get_ndbi(image,roi):\n",
        "  ndbi = image.normalizedDifference(['B11', 'B8']).rename('NDBI')\n",
        "  region =roi\n",
        "  # Use a mean reducer.\n",
        "  reducer = ee.Reducer.mean()\n",
        "\n",
        "  # Compute the unweighted mean.\n",
        "  ndbi_value = ndbi.select(['NDBI']).reduceRegion(**{ 'reducer': ee.Reducer.mean(),\n",
        "  'geometry': roi,\n",
        "  'maxPixels': 1e9})\n",
        "  return ndbi_value.getInfo()['NDBI']\n",
        "\n",
        "def get_ui(image,roi):\n",
        "    Ndvi = image.normalizedDifference(['B8', 'B4'])\n",
        "    Ndbi = image.normalizedDifference(['B11', 'B8'])\n",
        "    Ui = Ndbi.subtract(Ndvi).rename('Ui');\n",
        "    region = roi\n",
        "    reducer = ee.Reducer.mean()\n",
        "    Ui_value = Ui.select(['Ui']).reduceRegion(**{ 'reducer': ee.Reducer.mean(),\n",
        "  'geometry': roi,\n",
        "  'maxPixels': 1e9})\n",
        "    return Ui_value.getInfo()['Ui']\n",
        "\n",
        "\n",
        "def get_ndvi_image(image):\n",
        "  ndvi = image.normalizedDifference(['B8', 'B4']).rename('NDVI')\n",
        "  return ndvi\n",
        "\n",
        "def plot_image(img, paramters, cloud_name = \"CLOUDY_PIXEL_PERCENTAGE\"):\n",
        "  \n",
        "  cloud_pct = img.get(\"CLOUDY_PIXEL_PERCENTAGE\").getInfo()\n",
        "  # print(f'Cloud Cover (%): {cloud_pct}')\n",
        "\n",
        "  url = img.getThumbUrl(parameters)\n",
        "  response = requests.get(url)\n",
        "  \n",
        "  return cloud_pct, Image.open(BytesIO(response.content))\n",
        "\n",
        "image_list = []\n",
        "save_df = pd.DataFrame(columns=[\"raw_name\", \"image_name\",'ndvi_image' \"cloud_pct\",\"year\",\"time\",\"NDVI\",\"NDBI\",\"UI\"])\n",
        "\n",
        "for year in [\"2016\",\"2017\",\"2018\",\"2019\",\"2020\"]:\n",
        "  name = f\"{year}.png\" \n",
        "  if (year == \"2016\") :\n",
        "    image = (ee.ImageCollection('COPERNICUS/S2')\n",
        "              .filterBounds(roi)\n",
        "              .sort('CLOUDY_PIXEL_PERCENTAGE')\n",
        "              .filterDate(\"2016-04-16\", \"2016-04-28\")\n",
        "              .first()\n",
        "              .clip(roi))\n",
        "  elif (year == \"2017\"):\n",
        "     image = (ee.ImageCollection('COPERNICUS/S2')\n",
        "              .filterBounds(roi)\n",
        "              .sort('CLOUDY_PIXEL_PERCENTAGE')\n",
        "              .filterDate(range_year(year))\n",
        "              #.filterDate(\"2017-04-24\", \"2017-05-05\")\n",
        "              .first()\n",
        "              .clip(roi))\n",
        "  elif (year ==\"2018\"):\n",
        "     image = (ee.ImageCollection('COPERNICUS/S2')\n",
        "              .filterBounds(roi)\n",
        "              .sort('CLOUDY_PIXEL_PERCENTAGE')\n",
        "              .filterDate(range_year(year))\n",
        "              #.filterDate(\"2018-04-01\", \"2018-04-19\")\n",
        "              .first()\n",
        "              .clip(roi))\n",
        "  elif ( year == \"2020\"):\n",
        "     image = (ee.ImageCollection('COPERNICUS/S2')\n",
        "              .filterBounds(roi)\n",
        "              .sort('CLOUDY_PIXEL_PERCENTAGE')\n",
        "              .filterDate(range_year(year))\n",
        "              #.filterDate(\"2020-04-15\", \"2020-05-15\")\n",
        "              .first()\n",
        "              .clip(roi))\n",
        "  else :\n",
        "     image = (ee.ImageCollection('COPERNICUS/S2')\n",
        "              .filterBounds(roi)\n",
        "              .sort('CLOUDY_PIXEL_PERCENTAGE')\n",
        "              .filterDate(range_year(year))\n",
        "              #.filterDate(\"2019-04-01\", \"2019-05-01\")\n",
        "              .first()\n",
        "              .clip(roi))\n",
        "  parameters = {\n",
        "    'min': 0.0,\n",
        "    'max': 3000,\n",
        "    'bands': ['B4', 'B3', 'B2'],\n",
        "    'dimensions': 512,\n",
        "    'region': roi\n",
        "  }\n",
        "  cloud_pct, least_result = plot_image(image.resample('bicubic'), parameters,'CLOUDY_PIXEL_PERCENTAGE')\n",
        "  date = ee.Date(image.get('system:time_start'))\n",
        "  time = date.getInfo()['value']/1000.\n",
        "  classified = image.select(bands).classify(classifier)\n",
        "  ndvi = get_ndvi(image,roi)\n",
        "  ndbi = get_ndbi(image,roi)\n",
        "  ui = get_ui(image,roi)\n",
        "  image_list.append(least_result)\n",
        "\n",
        "  areaImage = (ee.Image.pixelArea().addBands(\n",
        "      classified))\n",
        "  areas = (areaImage.reduceRegion(\n",
        "    reducer =  ee.Reducer.sum().group(groupField = 1,groupName = 'class'),\n",
        "    geometry =  roi,\n",
        "    scale= 500,\n",
        "    maxPixels =  1e10\n",
        "    ));\n",
        "  each_class = areas.getInfo()\n",
        "  if(len(each_class['groups']) == 4) :\n",
        "    sum = round(each_class['groups'][0]['sum'] + each_class['groups'][1]['sum'] +each_class['groups'][2]['sum']+each_class['groups'][3]['sum'])\n",
        "    agri =  round(round(each_class['groups'][0]['sum']) / sum *100,2)\n",
        "    urban = round(round(each_class['groups'][1]['sum']) / sum*100,2)\n",
        "    water = round(round(each_class['groups'][2]['sum']) / sum*100,2)\n",
        "    forest = round(round(each_class['groups'][3]['sum']) / sum*100,2)\n",
        "  elif(len(each_class['groups'])==3):\n",
        "    sum = round(each_class['groups'][0]['sum'] + each_class['groups'][1]['sum'] +each_class['groups'][2]['sum'])\n",
        "    agri =  round(round(each_class['groups'][0]['sum']) / sum *100,2)\n",
        "    urban = round(round(each_class['groups'][1]['sum']) / sum*100,2)\n",
        "    water = 0\n",
        "    forest = round(round(each_class['groups'][2]['sum']) / sum*100,2)\n",
        "\n",
        "   # 메타 정보 데이터프레임에 저장\n",
        "  tmp_result = pd.Series({\"raw_name\" : image.getInfo()['id'], \"image_name\": name,  \"cloud_pct\": cloud_pct,\n",
        "                            \"year\": year, \"time\" : dt.utcfromtimestamp(time).strftime('%Y-%m-%d %H:%M:%S'),\"NDVI\" : ndvi,\"NDBI\" : ndbi,\"UI\" : ui,\"Agri\":agri,\"Urban\" : urban,\"Water\" : water,\"Forest\" : forest}).to_frame().T\n",
        "  save_df = save_df.append(tmp_result,ignore_index=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vnZFCbBj9Rkd"
      },
      "source": [
        "#table= ee.FeatureCollection(\"users/jinwoo95/hwacheon\")\n",
        "area = table.getInfo()['features'][0]['geometry']['coordinates']\n",
        "roi = ee.Geometry.Polygon(area)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F4LqIA8g-U-p"
      },
      "source": [
        "image_list[2]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Swwtylsa9E8e"
      },
      "source": [
        "table= ee.FeatureCollection(\"users/jinwoo95/real_chuncheon\")\n",
        "area = table.getInfo()['features'][0]['geometry']['coordinates']\n",
        "roi = ee.Geometry.Polygon(area)\n",
        "image = (ee.ImageCollection('COPERNICUS/S2')\n",
        "              .filterBounds(roi)\n",
        "              .sort('CLOUDY_PIXEL_PERCENTAGE')\n",
        "              .filterDate(\"2020-04-01\", \"2020-05-15\")\n",
        "              .first()\n",
        "              .clip(roi))\n",
        "parameters = {\n",
        "    'min': 0.0,\n",
        "    'max': 3000,\n",
        "    'bands': ['B4', 'B3', 'B2'],\n",
        "    'dimensions': 512,\n",
        "    'region': roi\n",
        "  }\n",
        "cloud_pct, least_result = plot_image(image.resample('bicubic'), parameters,'CLOUDY_PIXEL_PERCENTAGE')\n",
        "least_result"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HiG9d4yL98xb"
      },
      "source": [
        "from matplotlib import pyplot as plt\n",
        "x = [2016,2017,2018,2019,2020]\n",
        "y =  save_df['NDVI']\n",
        "y1 = save_df['NDBI']\n",
        "y2 = save_df['UI']\n",
        "\n",
        "plt.figure(figsize = (8,8)) \n",
        "plt.xlabel(\"Time\")\n",
        "plt.plot(x,y)\n",
        "plt.plot(x,y1)\n",
        "plt.plot(x,y2)\n",
        "plt.grid(10)\n",
        "plt.xticks([2016 ,2017, 2018, 2019 ,2020])\n",
        "plt.legend(['NDVI', 'NDBI','UI'])\n",
        "# 화면에 그래프를 보여줍니다\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7-02lQPdAiTE"
      },
      "source": [
        "image_list[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CKeVwKciXgw-"
      },
      "source": [
        "image_list[1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GN9z26mHXi0G"
      },
      "source": [
        "image_list[2]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tKmhfKVPXof2"
      },
      "source": [
        "image_list[3]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5jXCsoPIXprs"
      },
      "source": [
        "image_list[4]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AtCCUlW8g5hP"
      },
      "source": [
        "위성사진 획득하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HBqd9Xw9XseJ"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import math\n",
        "from datetime import datetime as dt\n",
        "table= ee.FeatureCollection(\"users/jinwoo95/pyeongchang\")\n",
        "area = table.getInfo()['features'][0]['geometry']['coordinates']\n",
        "roi = ee.Geometry.Polygon(area)\n",
        "image = (ee.ImageCollection('COPERNICUS/S2')\n",
        "              .filterBounds(roi)\n",
        "              .sort('CLOUDY_PIXEL_PERCENTAGE')\n",
        "              .filterDate(\"2016-04-16\", \"2016-04-28\")\n",
        "              .first()\n",
        "              .clip(roi))\n",
        "def plot_image(img, paramters, cloud_name = \"CLOUDY_PIXEL_PERCENTAGE\"):\n",
        "  \n",
        "  cloud_pct = img.get(\"CLOUDY_PIXEL_PERCENTAGE\").getInfo()\n",
        "  # print(f'Cloud Cover (%): {cloud_pct}')\n",
        "\n",
        "  url = img.getThumbUrl(parameters)\n",
        "  response = requests.get(url)\n",
        "  \n",
        "  return cloud_pct, Image.open(BytesIO(response.content))\n",
        "\n",
        "image_list = []\n",
        "save_df = pd.DataFrame(columns=[\"raw_name\", \"image_name\",'ndvi_image' \"cloud_pct\",\"year\",\"time\",\"NDVI\",\"NDBI\",\"UI\"])\n",
        "for year in [\"2016\",\"2017\",\"2018\",\"2019\",\"2020\"]:\n",
        "  name = f\"{year}.png\" \n",
        "  if (year == \"2016\") :\n",
        "    image = (ee.ImageCollection('COPERNICUS/S2')\n",
        "              .filterBounds(roi)\n",
        "              .sort('CLOUDY_PIXEL_PERCENTAGE')\n",
        "              .filterDate(\"2016-04-16\", \"2016-04-28\")\n",
        "              .first())\n",
        "              \n",
        "  elif (year == \"2017\"):\n",
        "     image = (ee.ImageCollection('COPERNICUS/S2')\n",
        "              .filterBounds(roi)\n",
        "              .sort('CLOUDY_PIXEL_PERCENTAGE')\n",
        "              .filterDate(\"2017-04-15\", \"2017-05-01\")\n",
        "              .first())\n",
        "            \n",
        "  elif (year ==\"2018\"):\n",
        "     image = (ee.ImageCollection('COPERNICUS/S2')\n",
        "              .filterBounds(roi)\n",
        "              .sort('CLOUDY_PIXEL_PERCENTAGE')\n",
        "              .filterDate(\"2018-04-01\", \"2018-04-19\")\n",
        "              .first())\n",
        "           \n",
        "  elif ( year == \"2020\"):\n",
        "     image = (ee.ImageCollection('COPERNICUS/S2')\n",
        "              .filterBounds(roi)\n",
        "              .sort('CLOUDY_PIXEL_PERCENTAGE')\n",
        "              .filterDate(\"2020-04-15\", \"2020-05-15\")\n",
        "              .first())\n",
        "          \n",
        "  else :\n",
        "     image = (ee.ImageCollection('COPERNICUS/S2')\n",
        "              .filterBounds(roi)\n",
        "              .sort('CLOUDY_PIXEL_PERCENTAGE')\n",
        "              .filterDate(\"2019-04-01\", \"2019-05-01\")\n",
        "              .first())\n",
        "             \n",
        "  parameters = {\n",
        "    'min': 0.0,\n",
        "    'max': 3000,\n",
        "    'bands': ['B4', 'B3', 'B2'],\n",
        "    'dimensions': 512,\n",
        "    'region': roi\n",
        "  }\n",
        "  cloud_pct, least_result = plot_image(image.resample('bicubic'), parameters,'CLOUDY_PIXEL_PERCENTAGE')\n",
        "  date = ee.Date(image.get('system:time_start'))\n",
        "  time = date.getInfo()['value']/1000.\n",
        "  image_list.append(least_result)\n",
        "   # 메타 정보 데이터프레임에 저장\n",
        "  tmp_result = pd.Series({\"raw_name\" : image.getInfo()['id'], \"image_name\": name,  \"cloud_pct\": cloud_pct,\n",
        "                            \"year\": year, \"time\" : dt.utcfromtimestamp(time).strftime('%Y-%m-%d %H:%M:%S')}).to_frame().T\n",
        "  save_df = save_df.append(tmp_result,ignore_index=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TrmVzBS5hID_"
      },
      "source": [
        "save_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t8MGY4g7hfO_"
      },
      "source": [
        "image_list[4]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QeVgJ8S5hiO-"
      },
      "source": [
        "#분류 전 데이터 학습 및 검증하기\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import math\n",
        "from datetime import datetime as dt\n",
        "def range_year(year):\n",
        "  return f\"{year}-04-01\", f\"{year}-05-01\"\n",
        "def calculate_alpha_ratio(image):\n",
        "  img_array = np.array(image)\n",
        "  return np.sum(img_array == 0) / img_array.size\n",
        "\n",
        "#알펜시아\n",
        "#lat = 37.658251\n",
        "#lon = 128.669856\n",
        "#진부역\n",
        "#lat = 37.642935\n",
        "#lon = 128.574451\n",
        "#올림픽 게이트웨이\n",
        "#lat = 37.668117\n",
        "#lon = 128.705676\n",
        "#자연휴양\n",
        "#lat = 37.705692\n",
        "#lon = 128.720683\n",
        "\n",
        "#평창역\n",
        "#lat = 37.562846\n",
        "#lon = 128.429930\n",
        "#춘천시\n",
        "#lat = 37.883078\n",
        "#lon =127.730863\n",
        "#강원도홍청군\n",
        "#lat = 37.697150\n",
        "#lon  = 127.888811\n",
        "#강원도 양구군\n",
        "#lat = 38.110184\n",
        "#lon =127.990013\n",
        "#강원도 인제 군청\n",
        "#lat = 38.069709\n",
        "#lon = 128.169734\n",
        "#강릉시청\n",
        "#lat = 37.752154\n",
        "#lon = 128.876049\n",
        "#정선군청\n",
        "#lat  = 37.394236\n",
        "#lon =  128.656869\n",
        "#인제군청\n",
        "#lat = 38.069747\n",
        "#lon = 128.169755\n",
        "#횡성 군청\n",
        "#lat = 37.491881\n",
        "#lon = 127.985079\n",
        "region = [\"춘천\",\"양구\",\"인제\",\"횡성\",\"강릉\",\"정선\",\"평창\"]\n",
        "loc = [[37.883078,127.730863],\n",
        "#강원도 양구군\n",
        "[38.110184,127.990013],\n",
        "#강원도 인제 군청\n",
        "[38.069709,128.169734],\n",
        "#횡성 군청\n",
        "[37.491881,127.985079],\n",
        "#강릉시청\n",
        "[37.752154,128.876049],\n",
        "#정선군청\n",
        "[37.394236,128.656869],\n",
        "#평창군청\n",
        "[37.370814, 128.390359]]\n",
        "\n",
        "def range_year(year):\n",
        "  return f\"{year}-04-01\", f\"{year}-05-01\"\n",
        "earth = EasyEarth('COPERNICUS/S2')\n",
        "CLOUD_NAME = \"CLOUDY_PIXEL_PERCENTAGE\" # \"CLOUD_COVER\"\n",
        "bands = ['B1', 'B2', 'B3', 'B4', 'B5', 'B6', 'B7', 'B8',\"B8A\",\"B9\",\"B10\",\"B11\",\"B12\"]\n",
        "#badns = [\"B4\",\"B8\",\"B11\"]\n",
        "\n",
        "save_df = pd.DataFrame(columns=[\"Region\",\"lat\", \"lon\",\"cloud_pct\",\"year\",\"time\",\"NDVI\",\"NDBI\",\"UI\",\"Agri\",\"Urban\",\"Water\",\"Forest\",\"image\"])\n",
        "image_list = []\n",
        "for i in range(len(loc)):\n",
        "  lat , lon = loc[i]\n",
        "  Region = region[i]\n",
        "  for year in [\"2016\",\"2017\",\"2018\",\"2019\",\"2020\"]:\n",
        "    name = f\"{lat}_{lon}_{year}.png\" \n",
        "    '''if (year == \"2016\") :\n",
        "      earth.select_AOI(lat,lon, 10, (\"2016-04-16\", \"2016-04-28\"), CLOUD_NAME, 10)\n",
        "    elif (year == \"2017\"):\n",
        "      earth.select_AOI(lat,lon, 10, (\"2017-04-15\", \"2017-05-01\"), CLOUD_NAME, 10)\n",
        "    elif (year ==\"2018\"):\n",
        "      earth.select_AOI(lat,lon, 10, (\"2018-04-01\", \"2018-04-19\"), CLOUD_NAME, 10)\n",
        "    elif ( year == \"2020\"):\n",
        "      earth.select_AOI(lat,lon, 10, (\"2020-04-15\", \"2020-05-15\"), CLOUD_NAME, 10)\n",
        "    else :\n",
        "      earth.select_AOI(lat,lon, 10, range_year(year), CLOUD_NAME, 10)\n",
        "  '''\n",
        "    earth.select_AOI(lat,lon, 10, range_year(year), CLOUD_NAME, 10)\n",
        "    parameters = {\n",
        "      'min': 0.0,\n",
        "      'max': 3000,\n",
        "      'bands': ['B4', 'B3', 'B2'],\n",
        "      'maxPixels': 1e12,\n",
        "      #'dimensions' : [5490,5490],\n",
        "      'scale' : 3,\n",
        "      'region': earth.AOI\n",
        "    }\n",
        "    \n",
        "    #earth.data_AOI.map(cloudMask)\n",
        "    geometry = earth.AOI\n",
        "    earth.sort_by(CLOUD_NAME)\n",
        "    i=0\n",
        "    while 1:\n",
        "      least_cloudy_img = earth.get_collections_at(i)\n",
        "      least_cloudy_img = least_cloudy_img.clip(earth.AOI)\n",
        "      cloud_pct, least_result = earth.plot_image(least_cloudy_img.resample('bicubic'), parameters, CLOUD_NAME)\n",
        "      alpha = calculate_alpha_ratio(least_result)\n",
        "      i+=1\n",
        "      if(alpha <0.1):\n",
        "        break;\n",
        "    date = ee.Date(least_cloudy_img.get('system:time_start'))\n",
        "    time = date.getInfo()['value']/1000.\n",
        "    classified = least_cloudy_img.select(bands).classify(classifier)\n",
        "    ndvi = earth.get_ndvi(least_cloudy_img)\n",
        "    ndbi = earth.get_ndbi(least_cloudy_img)\n",
        "    ui = earth.get_ui(least_cloudy_img)\n",
        "    cloud_pct, least_result = earth.plot_image(least_cloudy_img.resample('bicubic'), parameters, CLOUD_NAME)\n",
        "    image_list.append(least_result)\n",
        "    \n",
        "    #클래스 별 면적 구하기\n",
        "    areaImage = (ee.Image.pixelArea().addBands(\n",
        "        classified))\n",
        "    areas = (areaImage.reduceRegion(\n",
        "      reducer =  ee.Reducer.sum().group(groupField = 1,groupName = 'class'),\n",
        "      geometry =  geometry,\n",
        "      scale= 500,\n",
        "      maxPixels =  1e10\n",
        "      ));\n",
        "    each_class = areas.getInfo()\n",
        "    if(len(each_class['groups']) == 4) :\n",
        "      sum = round(each_class['groups'][0]['sum'] + each_class['groups'][1]['sum'] +each_class['groups'][2]['sum']+each_class['groups'][3]['sum'])\n",
        "      agri =  round(round(each_class['groups'][0]['sum']) / sum *100,2)\n",
        "      urban = round(round(each_class['groups'][1]['sum']) / sum*100,2)\n",
        "      water = round(round(each_class['groups'][2]['sum']) / sum*100,2)\n",
        "      forest = round(round(each_class['groups'][3]['sum']) / sum*100,2)\n",
        "    elif(len(each_class['groups'])==3):\n",
        "      sum = round(each_class['groups'][0]['sum'] + each_class['groups'][1]['sum'] +each_class['groups'][2]['sum'])\n",
        "      agri =  round(round(each_class['groups'][0]['sum']) / sum *100,2)\n",
        "      urban = round(round(each_class['groups'][1]['sum']) / sum*100,2)\n",
        "      water = 0\n",
        "      forest = round(round(each_class['groups'][2]['sum']) / sum*100,2)\n",
        "                  \n",
        "\n",
        "    #학습된 모델로 이미지 분류\n",
        "\n",
        "    # 메타 정보 데이터프레임에 저장\n",
        "    tmp_result = pd.Series({\"Region\" : Region, \"lat\": lat, \"lon\": lon, \"cloud_pct\": cloud_pct,\n",
        "                              \"year\": year, \"time\" : dt.utcfromtimestamp(time).strftime('%Y-%m-%d %H:%M:%S'),\"NDVI\" : ndvi,\"NDBI\": ndbi,\"UI\": ui,\"Agri\":agri,\"Urban\" : urban,\"Water\" : water,\"Forest\" : forest,\"image\" :least_cloudy_img }).to_frame().T\n",
        "    save_df = save_df.append(tmp_result,ignore_index=True)\n",
        "\n",
        "save_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CYEWbIVEnuYa"
      },
      "source": [
        "#분류 전 데이터 학습 및 검증하기\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import math\n",
        "from datetime import datetime as dt\n",
        "def range_year(year):\n",
        "  return f\"{year}-04-01\", f\"{year}-05-01\"\n",
        "def calculate_alpha_ratio(image):\n",
        "  img_array = np.array(image)\n",
        "  return np.sum(img_array == 0) / img_array.size\n",
        "\n",
        "#알펜시아\n",
        "#lat = 37.658251\n",
        "#lon = 128.669856\n",
        "#진부역\n",
        "#lat = 37.642935\n",
        "#lon = 128.574451\n",
        "#올림픽 게이트웨이\n",
        "#lat = 37.668117\n",
        "#lon = 128.705676\n",
        "#자연휴양\n",
        "#lat = 37.705692\n",
        "#lon = 128.720683\n",
        "#평창역\n",
        "#lat = 37.562846\n",
        "#lon = 128.429930\n",
        "\n",
        "#춘천시\n",
        "#lat = 37.883078\n",
        "#lon =127.730863\n",
        "#강원도홍청군\n",
        "#lat = 37.697150\n",
        "#lon  = 127.888811\n",
        "#강원도 양구군\n",
        "#lat = 38.110184\n",
        "#lon =127.990013\n",
        "#강원도 인제 군청\n",
        "#lat = 38.069709\n",
        "#lon = 128.169734\n",
        "#강릉시청\n",
        "#lat = 37.752154\n",
        "#lon = 128.876049\n",
        "#정선군청\n",
        "#lat  = 37.394236\n",
        "#lon =  128.656869\n",
        "#인제군청\n",
        "#lat = 38.069747\n",
        "#lon = 128.169755\n",
        "#횡성 군청\n",
        "#lat = 37.491881\n",
        "#lon = 127.985079\n",
        "region = [\"춘천\",\"양구\",\"인제\",\"횡성\",\"강릉\",\"정선\",\"평창\"]\n",
        "loc = [\n",
        "[37.370814, 128.390359]]\n",
        "\n",
        "def range_year(year):\n",
        "  return f\"{year}-04-01\", f\"{year}-05-01\"\n",
        "earth = EasyEarth('COPERNICUS/S2')\n",
        "CLOUD_NAME = \"CLOUDY_PIXEL_PERCENTAGE\" # \"CLOUD_COVER\"\n",
        "bands = ['B1', 'B2', 'B3', 'B4', 'B5', 'B6', 'B7', 'B8',\"B8A\",\"B9\",\"B10\",\"B11\",\"B12\"]\n",
        "#badns = [\"B4\",\"B8\",\"B11\"]\n",
        "\n",
        "save_df = pd.DataFrame(columns=[\"Region\",\"lat\", \"lon\",\"cloud_pct\",\"year\",\"time\",\"NDVI\",\"NDBI\",\"image\"])\n",
        "image_list = []\n",
        "for i in range(len(loc)):\n",
        "  lat , lon = loc[i]\n",
        "  Region = region[i]\n",
        "  for year in [\"2016\",\"2017\",\"2018\",\"2019\",\"2020\"]:\n",
        "    name = f\"{lat}_{lon}_{year}.png\" \n",
        "    '''if (year == \"2016\") :\n",
        "      earth.select_AOI(lat,lon, 10, (\"2016-04-16\", \"2016-04-28\"), CLOUD_NAME, 10)\n",
        "    elif (year == \"2017\"):\n",
        "      earth.select_AOI(lat,lon, 10, (\"2017-04-15\", \"2017-05-01\"), CLOUD_NAME, 10)\n",
        "    elif (year ==\"2018\"):\n",
        "      earth.select_AOI(lat,lon, 10, (\"2018-04-01\", \"2018-04-19\"), CLOUD_NAME, 10)\n",
        "    elif ( year == \"2020\"):\n",
        "      earth.select_AOI(lat,lon, 10, (\"2020-04-15\", \"2020-05-15\"), CLOUD_NAME, 10)\n",
        "    else :\n",
        "      earth.select_AOI(lat,lon, 10, range_year(year), CLOUD_NAME, 10)\n",
        "  '''\n",
        "    earth.select_AOI(lat,lon, 10, range_year(year), CLOUD_NAME, 10)\n",
        "    parameters = {\n",
        "      'min': 0.0,\n",
        "      'max': 3000,\n",
        "      'bands': ['B4', 'B3', 'B2'],\n",
        "      'maxPixels': 1e12,\n",
        "      #'dimensions' : [5490,5490],\n",
        "      'scale' : 3,\n",
        "      'region': earth.AOI\n",
        "    }\n",
        "    \n",
        "    #earth.data_AOI.map(cloudMask)\n",
        "    geometry = earth.AOI\n",
        "    earth.sort_by(CLOUD_NAME)\n",
        "    i=0\n",
        "    while 1:\n",
        "      least_cloudy_img = earth.get_collections_at(i)\n",
        "      least_cloudy_img = least_cloudy_img.clip(earth.AOI)\n",
        "      cloud_pct, least_result = earth.plot_image(least_cloudy_img.resample('bicubic'), parameters, CLOUD_NAME)\n",
        "      alpha = calculate_alpha_ratio(least_result)\n",
        "      i+=1\n",
        "      if(alpha <0.1):\n",
        "        break;\n",
        "    date = ee.Date(least_cloudy_img.get('system:time_start'))\n",
        "    time = date.getInfo()['value']/1000.\n",
        "    ndvi = earth.get_ndvi(least_cloudy_img)\n",
        "    ndbi = earth.get_ndbi(least_cloudy_img)\n",
        "    ui = earth.get_ui(least_cloudy_img)\n",
        "    cloud_pct, least_result = earth.plot_image(least_cloudy_img.resample('bicubic'), parameters, CLOUD_NAME)\n",
        "    image_list.append(least_result)\n",
        "\n",
        "    #학습된 모델로 이미지 분류\n",
        "\n",
        "    # 메타 정보 데이터프레임에 저장\n",
        "    tmp_result = pd.Series({\"Region\" : Region, \"lat\": lat, \"lon\": lon, \"cloud_pct\": cloud_pct,\n",
        "                              \"year\": year, \"time\" : dt.utcfromtimestamp(time).strftime('%Y-%m-%d %H:%M:%S'),\"NDVI\" : ndvi,\"NDBI\": ndbi,\"UI\": ui,\"image\" :least_cloudy_img }).to_frame().T\n",
        "    save_df = save_df.append(tmp_result,ignore_index=True)\n",
        "\n",
        "save_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vz7J1z1hnbJt"
      },
      "source": [
        "image_list[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PCo1FThlrTm2"
      },
      "source": [
        "# 다중회귀분석"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bRdRr_KQrWwk"
      },
      "source": [
        "!pip install plotly_express\n",
        "!pip install geopandas\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import geopandas as gpd\n",
        "from pandas import DataFrame\n",
        "import matplotlib.pyplot as plt\n",
        "import plotly_express as px\n",
        "import matplotlib as mpl\n",
        "# 그래프 한글 환경 설정\n",
        "%config InlineBackend.figure_format = 'retina'\n",
        "#!apt -qq -y install fonts-nanum\n",
        "import matplotlib.font_manager as fm\n",
        "from geopandas import GeoDataFrame\n",
        "import seaborn as sns\n",
        "from sklearn.preprocessing import MaxAbsScaler,RobustScaler\n",
        "import statsmodels.formula.api as sm  \n",
        "import pandas as pd # csv file \n",
        "from sklearn.linear_model import LinearRegression # 선형회귀모델 생성 \n",
        "from sklearn.model_selection import train_test_split # train/test set 생성 \n",
        "from sklearn.metrics import mean_squared_error # MSE : 평균제곱오차 - model 평가 \n",
        "fontpath = '/usr/share/fonts/truetype/nanum/NanumBarunGothic.ttf'\n",
        "font = fm.FontProperties(fname=fontpath, size=9)\n",
        "plt.rc('font', family='NanumBarunGothic')\n",
        "mpl.font_manager._rebuild()\n",
        "import warnings\n",
        "warnings.filterwarnings(action='ignore')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QFEU34wGrXzO"
      },
      "source": [
        "data = pd.read_excel(\"olympic.xlsx\",index_col=True)\n",
        "data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cc-h2wMTr-HV"
      },
      "source": [
        "#분류 전 데이터 학습 및 검증하기\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import math\n",
        "from datetime import datetime as dt\n",
        "\n",
        "region = [\"춘천\",\"양구\",\"인제\",\"횡성\",\"강릉\",\"정선\",\"평창\"]\n",
        "loc = [[37.883078,127.730863],\n",
        "#강원도 양구군\n",
        "[38.110184,127.990013],\n",
        "#강원도 인제 군청\n",
        "[38.069709,128.169734],\n",
        "#횡성 군청\n",
        "[37.491881,127.985079],\n",
        "#강릉시청\n",
        "[37.752154,128.876049],\n",
        "#정선군청\n",
        "[37.394236,128.656869],\n",
        "#평창군청\n",
        "[37.370814, 128.390359]]\n",
        "def range_year(year):\n",
        "  return f\"{year}-04-01\", f\"{year}-05-01\"\n",
        "earth = EasyEarth('COPERNICUS/S2')\n",
        "CLOUD_NAME = \"CLOUDY_PIXEL_PERCENTAGE\" # \"CLOUD_COVER\"\n",
        "bands = ['B1', 'B2', 'B3', 'B4', 'B5', 'B6', 'B7', 'B8',\"B8A\",\"B9\",\"B10\",\"B11\",\"B12\"]\n",
        "#badns = [\"B4\",\"B8\",\"B11\"]\n",
        "\n",
        "save_df = pd.DataFrame(columns=[\"Region\",\"lat\", \"lon\",\"cloud_pct\",\"year\",\"time\",\"NDVI\",\"NDBI\",\"UI\",\"Agri\",\"Urban\",\"Water\",\"Forest\",\"image\"])\n",
        "image_list = []\n",
        "for i in range(len(loc)):\n",
        "  lat , lon = loc[i]\n",
        "  Region = region[i]\n",
        "  for year in [\"2016\",\"2017\",\"2018\",\"2019\",\"2020\"]:\n",
        "    name = f\"{lat}_{lon}_{year}.png\" \n",
        "    '''if (year == \"2016\") :\n",
        "      earth.select_AOI(lat,lon, 10, (\"2016-04-16\", \"2016-04-28\"), CLOUD_NAME, 10)\n",
        "    elif (year == \"2017\"):\n",
        "      earth.select_AOI(lat,lon, 10, (\"2017-04-15\", \"2017-05-01\"), CLOUD_NAME, 10)\n",
        "    elif (year ==\"2018\"):\n",
        "      earth.select_AOI(lat,lon, 10, (\"2018-04-01\", \"2018-04-19\"), CLOUD_NAME, 10)\n",
        "    elif ( year == \"2020\"):\n",
        "      earth.select_AOI(lat,lon, 10, (\"2020-04-15\", \"2020-05-15\"), CLOUD_NAME, 10)\n",
        "    else :\n",
        "      earth.select_AOI(lat,lon, 10, range_year(year), CLOUD_NAME, 10)\n",
        "  '''\n",
        "    earth.select_AOI(lat,lon, 10, range_year(year), CLOUD_NAME, 10)\n",
        "    parameters = {\n",
        "      'min': 0.0,\n",
        "      'max': 3000,\n",
        "      'bands': ['B4', 'B3', 'B2'],\n",
        "      'maxPixels': 1e12,\n",
        "      #'dimensions' : [5490,5490],\n",
        "      'scale' : 3,\n",
        "      'region': earth.AOI\n",
        "    }\n",
        "    \n",
        "    #earth.data_AOI.map(cloudMask)\n",
        "    geometry = earth.AOI\n",
        "    earth.sort_by(CLOUD_NAME)\n",
        "    i=0\n",
        "    while 1:\n",
        "      least_cloudy_img = earth.get_collections_at(i)\n",
        "      least_cloudy_img = least_cloudy_img.clip(earth.AOI)\n",
        "      cloud_pct, least_result = earth.plot_image(least_cloudy_img.resample('bicubic'), parameters, CLOUD_NAME)\n",
        "      alpha = calculate_alpha_ratio(least_result)\n",
        "      i+=1\n",
        "      if(alpha <0.1):\n",
        "        break;\n",
        "    date = ee.Date(least_cloudy_img.get('system:time_start'))\n",
        "    time = date.getInfo()['value']/1000.\n",
        "    classified = least_cloudy_img.select(bands).classify(classifier)\n",
        "    ndvi = earth.get_ndvi(least_cloudy_img)\n",
        "    ndbi = earth.get_ndbi(least_cloudy_img)\n",
        "    ui = earth.get_ui(least_cloudy_img)\n",
        "    cloud_pct, least_result = earth.plot_image(least_cloudy_img.resample('bicubic'), parameters, CLOUD_NAME)\n",
        "    image_list.append(least_result)\n",
        "    \n",
        "    #클래스 별 면적 구하기\n",
        "    areaImage = (ee.Image.pixelArea().addBands(\n",
        "        classified))\n",
        "    areas = (areaImage.reduceRegion(\n",
        "      reducer =  ee.Reducer.sum().group(groupField = 1,groupName = 'class'),\n",
        "      geometry =  geometry,\n",
        "      scale= 500,\n",
        "      maxPixels =  1e10\n",
        "      ));\n",
        "    each_class = areas.getInfo()\n",
        "    if(len(each_class['groups']) == 4) :\n",
        "      sum = round(each_class['groups'][0]['sum'] + each_class['groups'][1]['sum'] +each_class['groups'][2]['sum']+each_class['groups'][3]['sum'])\n",
        "      agri =  round(round(each_class['groups'][0]['sum']) / sum *100,2)\n",
        "      urban = round(round(each_class['groups'][1]['sum']) / sum*100,2)\n",
        "      water = round(round(each_class['groups'][2]['sum']) / sum*100,2)\n",
        "      forest = round(round(each_class['groups'][3]['sum']) / sum*100,2)\n",
        "    elif(len(each_class['groups'])==3):\n",
        "      sum = round(each_class['groups'][0]['sum'] + each_class['groups'][1]['sum'] +each_class['groups'][2]['sum'])\n",
        "      agri =  round(round(each_class['groups'][0]['sum']) / sum *100,2)\n",
        "      urban = round(round(each_class['groups'][1]['sum']) / sum*100,2)\n",
        "      water = 0\n",
        "      forest = round(round(each_class['groups'][2]['sum']) / sum*100,2)\n",
        "                  \n",
        "\n",
        "    #학습된 모델로 이미지 분류\n",
        "\n",
        "    # 메타 정보 데이터프레임에 저장\n",
        "    tmp_result = pd.Series({\"Region\" : Region, \"lat\": lat, \"lon\": lon, \"cloud_pct\": cloud_pct,\n",
        "                              \"year\": year, \"time\" : dt.utcfromtimestamp(time).strftime('%Y-%m-%d %H:%M:%S'),\"NDVI\" : ndvi,\"NDBI\": ndbi,\"UI\": ui,\"Agri\":agri,\"Urban\" : urban,\"Water\" : water,\"Forest\" : forest,\"image\" :least_cloudy_img }).to_frame().T\n",
        "    save_df = save_df.append(tmp_result,ignore_index=True)\n",
        "\n",
        "save_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BqVIWa81B4ad"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mN_3DFnCtqwg"
      },
      "source": [
        "# Final 자료 정리"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CSWFCjkutsJ2"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kRb_MhMGttM-"
      },
      "source": [
        "## 각 특구별 분류 지수 추출"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "749H24FEtwzF"
      },
      "source": [
        "#분류 전 데이터 학습 및 검증하기\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import math\n",
        "from datetime import datetime as dt\n",
        "def range_year(year):\n",
        "  return f\"{year}-04-01\", f\"{year}-05-01\"\n",
        "#알펜시아\n",
        "#lat = 37.658251\n",
        "#lon = 128.669856\n",
        "#진부역\n",
        "#lat = 37.642935\n",
        "#lon = 128.574451\n",
        "#올림픽 게이트웨이\n",
        "#lat = 37.668117\n",
        "#lon = 128.705676\n",
        "#자연휴양\n",
        "#lat = 37.705692\n",
        "#lon = 128.720683\n",
        "#평창역\n",
        "#lat = 37.562846\n",
        "#lon = 128.429930\n",
        "#위의 순서와 같이 구성\n",
        "loc = [[37.658251,128.669856],[37.642935,128.574451],[37.668117,128.705676],[37.705692,128.720683],[37.562846,128.429930]]\n",
        "earth = EasyEarth('COPERNICUS/S2')\n",
        "CLOUD_NAME = \"CLOUDY_PIXEL_PERCENTAGE\" # \"CLOUD_COVER\"\n",
        "bands = ['B1', 'B2', 'B3', 'B4', 'B5', 'B6', 'B7', 'B8',\"B8A\",\"B9\",\"B10\",\"B11\",\"B12\"]\n",
        "#badns = [\"B4\",\"B8\",\"B11\"]\n",
        "save_df = pd.DataFrame(columns=[\"Region\",\"lat\", \"lon\", \"image_name\",\"cloud_pct\",\"year\",\"time\",\"NDVI\",\"NDBI\",\"UI\",\"Agri\",\"Urban\",\"Water\",\"Forest\"])\n",
        "region = [\"알펜시아\",\"진부역\",\"올림픽 게이트웨이\",\"자연휴양\",\"평창역\"]\n",
        "image_list = []\n",
        "for i in range(len(loc)):\n",
        "  lat , lon = loc[i]\n",
        "  Region = region[i]\n",
        "  for year in [\"2016\",\"2017\",\"2018\",\"2019\",\"2020\"]:\n",
        "    name = f\"{lat}_{lon}_{year}.png\" \n",
        "    if (year == \"2016\") :\n",
        "      earth.select_AOI(lat,lon, 10, (\"2016-04-16\", \"2016-04-28\"), CLOUD_NAME, 10)\n",
        "    elif (year == \"2017\"):\n",
        "      earth.select_AOI(lat,lon, 10, (\"2017-04-15\", \"2017-05-01\"), CLOUD_NAME, 10)\n",
        "    elif (year ==\"2018\"):\n",
        "      earth.select_AOI(lat,lon, 10, (\"2018-04-01\", \"2018-04-19\"), CLOUD_NAME, 10)\n",
        "    elif ( year == \"2020\"):\n",
        "      earth.select_AOI(lat,lon, 10, (\"2020-04-15\", \"2020-05-15\"), CLOUD_NAME, 10)\n",
        "    else :\n",
        "      earth.select_AOI(lat,lon, 10, range_year(year), CLOUD_NAME, 10)\n",
        "\n",
        "    parameters = {\n",
        "      'min': 0.0,\n",
        "      'max': 3000,\n",
        "      'bands': ['B4', 'B3', 'B2'],\n",
        "      'dimensions': 512,\n",
        "      'region': earth.AOI\n",
        "    }\n",
        "    #earth.data_AOI.map(cloudMask)\n",
        "    geometry = earth.AOI\n",
        "    earth.sort_by(CLOUD_NAME)\n",
        "    least_cloudy_img = earth.get_collections_at(0)\n",
        "    least_cloudy_img = least_cloudy_img.clip(earth.AOI)\n",
        "    cloud_pct, least_result = earth.plot_image(least_cloudy_img.resample('bicubic'), parameters, CLOUD_NAME)\n",
        "    date = ee.Date(least_cloudy_img.get('system:time_start'))\n",
        "    time = date.getInfo()['value']/1000.\n",
        "    classified = least_cloudy_img.select(bands).classify(classifier)\n",
        "    ndvi = earth.get_ndvi(least_cloudy_img)\n",
        "    ndbi = earth.get_ndbi(least_cloudy_img)\n",
        "    ui = earth.get_ui(least_cloudy_img)\n",
        "    cloud_pct, least_result = earth.plot_image(least_cloudy_img.resample('bicubic'), parameters, CLOUD_NAME)\n",
        "    image_list.append(least_result)\n",
        "    \n",
        "    #클래스 별 면적 구하기\n",
        "    areaImage = (ee.Image.pixelArea().addBands(\n",
        "        classified))\n",
        "    areas = (areaImage.reduceRegion(\n",
        "      reducer =  ee.Reducer.sum().group(groupField = 1,groupName = 'class'),\n",
        "      geometry =  geometry,\n",
        "      scale= 500,\n",
        "      maxPixels =  1e10\n",
        "      ));\n",
        "    each_class = areas.getInfo()\n",
        "    if(len(each_class['groups']) == 4) :\n",
        "      sum = round(each_class['groups'][0]['sum'] + each_class['groups'][1]['sum'] +each_class['groups'][2]['sum']+each_class['groups'][3]['sum'])\n",
        "      agri =  round(round(each_class['groups'][0]['sum']) / sum *100,2)\n",
        "      urban = round(round(each_class['groups'][1]['sum']) / sum*100,2)\n",
        "      water = round(round(each_class['groups'][2]['sum']) / sum*100,2)\n",
        "      forest = round(round(each_class['groups'][3]['sum']) / sum*100,2)\n",
        "    elif(len(each_class['groups'])==3):\n",
        "      sum = round(each_class['groups'][0]['sum'] + each_class['groups'][1]['sum'] +each_class['groups'][2]['sum'])\n",
        "      agri =  round(round(each_class['groups'][0]['sum']) / sum *100,2)\n",
        "      urban = round(round(each_class['groups'][1]['sum']) / sum*100,2)\n",
        "      water = 0\n",
        "      forest = round(round(each_class['groups'][2]['sum']) / sum*100,2)\n",
        "                  \n",
        "\n",
        "    #학습된 모델로 이미지 분류\n",
        "\n",
        "    # 메타 정보 데이터프레임에 저장\n",
        "    tmp_result = pd.Series({\"Region\": Region,\"lat\": lat, \"lon\": lon,  \"image_name\": name,  \"cloud_pct\": cloud_pct,\n",
        "                              \"year\": year, \"time\" : dt.utcfromtimestamp(time).strftime('%Y-%m-%d %H:%M:%S'),\"Agri\":agri,\"Urban\" : urban,\"Water\" : water,\"Forest\" : forest}).to_frame().T\n",
        "    save_df = save_df.append(tmp_result,ignore_index=True)\n",
        "\n",
        "save_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cBIEFHKU0ki7"
      },
      "source": [
        "save_df.to_csv('C:/Users/wlsdn/OneDrive/바탕 화면/qqq.csv',encoding= 'UTF-8')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9pBomDNWuKV5"
      },
      "source": [
        "#알펜시아\n",
        "#lat = 37.658251\n",
        "#lon = 128.669856\n",
        "#진부역\n",
        "#lat = 37.642935\n",
        "#lon = 128.574451\n",
        "#올림픽 게이트웨이\n",
        "#lat = 37.668117\n",
        "#lon = 128.705676\n",
        "#자연휴양\n",
        "#lat = 37.705692\n",
        "#lon = 128.720683\n",
        "#평창역\n",
        "#lat = 37.562846\n",
        "#lon = 128.429930\n",
        "loc = [[37.658251,128.669856],[37.642935,128.574451],[37.668117,128.705676],[37.705692,128.720683],[37.562846,128.429930]]\n",
        "for i in loca:\n",
        "  print(i)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ou13uQyuudm9"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}